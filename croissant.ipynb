{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlcroissant as mlc\n",
    "\n",
    "# FileObjects and FileSets define the resources of the dataset.\n",
    "distribution = [\n",
    "    # gpt-3 is hosted on a GitHub repository:\n",
    "    mlc.FileObject(\n",
    "        id=\"github-repository\",\n",
    "        name=\"github-repository\",\n",
    "        description=\"Generalized Firing Rate Neurons repository on GitHub.\",\n",
    "        content_url=\"https://github.com/AllenInstitute/GRNN\",\n",
    "        encoding_format=\"git+https\",\n",
    "        sha256=\"main\",\n",
    "    ),\n",
    "    # Within that repository, a FileSet lists all JSONL files:\n",
    "    mlc.FileSet(\n",
    "        id=\"jsonl-files\",\n",
    "        name=\"jsonl-files\",\n",
    "        description=\"JSON files are hosted on the GitHub repository.\",\n",
    "        contained_in=[\"github-repository\"],\n",
    "        encoding_format=\"application/jsonlines\",\n",
    "        includes=\"model/*.jsonl\",\n",
    "    ),\n",
    "]\n",
    "record_sets = [\n",
    "    \n",
    "\n",
    "    # RecordSets contains records in the dataset.\n",
    "    mlc.RecordSet(\n",
    "        id=\"jsonl\",\n",
    "        name=\"jsonl\",\n",
    "        # Each record has one or many fields...\n",
    "        fields=[\n",
    "            # Fields can be extracted from the FileObjects/FileSets.\n",
    "            mlc.Field(\n",
    "                id=\"jsonl/cell_id\",\n",
    "                name=\"cell_id\",\n",
    "                description=\"\",\n",
    "                data_types=mlc.DataType.INTEGER,\n",
    "                source=mlc.Source(\n",
    "                    file_set=\"jsonl-files\",\n",
    "                    # Extract the field from the column of a FileObject/FileSet:\n",
    "                    extract=mlc.Extract(column=\"cell_id\"),\n",
    "                ),\n",
    "            ),\n",
    "            mlc.Field(\n",
    "                id=\"jsonl/cre-line\",\n",
    "                name=\"cre-line\",\n",
    "                description=\"The expected completion of the promt.\",\n",
    "                data_types=mlc.DataType.TEXT,\n",
    "                source=mlc.Source(\n",
    "                    file_set=\"jsonl-files\",\n",
    "                    extract=mlc.Extract(column=\"cre-line\"),\n",
    "                ),\n",
    "            ),\n",
    "            mlc.Field(\n",
    "                id=\"jsonl/bin_size\",\n",
    "                name=\"bin_size\",\n",
    "                description=(\n",
    "                    \"The machine learning task appearing as the name of the\"\n",
    "                    \" file.\"\n",
    "                ),\n",
    "                data_types=mlc.DataType.INTEGER,\n",
    "                source=mlc.Source(\n",
    "                    file_set=\"jsonl-files\",\n",
    "                    extract=mlc.Extract(column=\"bin_size\"),\n",
    "                ),\n",
    "            ),\n",
    "            mlc.Field(\n",
    "                id=\"jsonl/actv_bin_size\",\n",
    "                name=\"actv_bin_size\",\n",
    "                description=(\n",
    "                    \"The machine learning task appearing as the name of the\"\n",
    "                    \" file.\"\n",
    "                ),\n",
    "                data_types=mlc.DataType.INTEGER,\n",
    "                source=mlc.Source(\n",
    "                    file_set=\"jsonl-files\",\n",
    "                    extract=mlc.Extract(column=\"actv_bin_size\"),\n",
    "                ),\n",
    "            ),\n",
    "            mlc.Field(\n",
    "                id=\"jsonl/val_evr\",\n",
    "                name=\"val_evr\",\n",
    "                description=(\n",
    "                    \"The machine learning task appearing as the name of the\"\n",
    "                    \" file.\"\n",
    "                ),\n",
    "                data_types=mlc.DataType.FLOAT,\n",
    "                source=mlc.Source(\n",
    "                    file_set=\"jsonl-files\",\n",
    "                    extract=mlc.Extract(column=\"val_evr\"),\n",
    "                ),\n",
    "            ),\n",
    "            mlc.Field(\n",
    "                id=\"jsonl/test_evr\",\n",
    "                name=\"test_evr\",\n",
    "                description=(\n",
    "                    \"The machine learning task appearing as the name of the\"\n",
    "                    \" file.\"\n",
    "                ),\n",
    "                data_types=mlc.DataType.FLOAT,\n",
    "                source=mlc.Source(\n",
    "                    file_set=\"jsonl-files\",\n",
    "                    extract=mlc.Extract(column=\"test_evr\"),\n",
    "                ),\n",
    "            ),\n",
    "            mlc.Field(\n",
    "                id=\"jsonl/train_loss\",\n",
    "                name=\"train_loss\",\n",
    "                description=(\n",
    "                    \"The machine learning task appearing as the name of the\"\n",
    "                    \" file.\"\n",
    "                ),\n",
    "                data_types=mlc.DataType.FLOAT,\n",
    "                source=mlc.Source(\n",
    "                    file_set=\"jsonl-files\",\n",
    "                    extract=mlc.Extract(column=\"train_loss\"),\n",
    "                ),\n",
    "            ),\n",
    "            mlc.Field(\n",
    "                id=\"jsonl/test_loss\",\n",
    "                name=\"test_loss\",\n",
    "                description=(\n",
    "                    \"The machine learning task appearing as the name of the\"\n",
    "                    \" file.\"\n",
    "                ),\n",
    "                data_types=mlc.DataType.FLOAT,\n",
    "                source=mlc.Source(\n",
    "                    file_set=\"jsonl-files\",\n",
    "                    extract=mlc.Extract(column=\"test_loss\"),\n",
    "                ),\n",
    "            ),\n",
    "            mlc.Field(\n",
    "                id=\"jsonl/params\",\n",
    "                name=\"params\",\n",
    "                description=(\n",
    "                    \"The machine learning task appearing as the name of the\"\n",
    "                    \" file.\"\n",
    "                ),\n",
    "                data_types=mlc.DataType.TEXT,\n",
    "                source=mlc.Source(\n",
    "                    file_set=\"jsonl-files\",\n",
    "                    extract=mlc.Extract(column=\"params\"),\n",
    "                ),\n",
    "                sub_fields = [\n",
    "                    mlc.Field(\n",
    "                        id=\"jsonl/params/a\",\n",
    "                        name=\"a\",\n",
    "                        description=\"The expected completion of the promt.\",\n",
    "                        data_types=mlc.DataType.FLOAT,\n",
    "                        repeated=True,\n",
    "                        source=mlc.Source(\n",
    "                            #field=\"id=jsonl/params\",\n",
    "                            file_set=\"jsonl-files\",\n",
    "                            \n",
    "                            extract=mlc.Extract(column=\"params\"),\n",
    "                            transforms=[mlc.Transform(json_path=\"a[0][0:4]\")],\n",
    "                        ),\n",
    "                    ),\n",
    "                ],\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "]\n",
    "\n",
    "# Metadata contains information about the dataset.\n",
    "metadata = mlc.Metadata(\n",
    "    name=\"gpt-3\",\n",
    "    # Descriptions can contain plain text or markdown.\n",
    "    description=(\n",
    "        \"Recent work has demonstrated substantial gains on many NLP tasks and\"\n",
    "        \" benchmarks by pre-training on a large corpus of text followed by\"\n",
    "        \" fine-tuning on a specific task. While typically task-agnostic in\"\n",
    "        \" architecture, this method still requires task-specific fine-tuning\"\n",
    "        \" datasets of thousands or tens of thousands of examples. By contrast,\"\n",
    "        \" humans can generally perform a new language task from only a few\"\n",
    "        \" examples or from simple instructions \\u2013 something which current\"\n",
    "        \" NLP systems still largely struggle to do. Here we show that scaling\"\n",
    "        \" up language models greatly improves task-agnostic, few-shot\"\n",
    "        \" performance, sometimes even reaching competitiveness with prior\"\n",
    "        \" state-of-the-art fine-tuning approaches. Specifically, we train\"\n",
    "        \" GPT-3, an autoregressive language model with 175 billion parameters,\"\n",
    "        \" 10x more than any previous non-sparse language model, and test its\"\n",
    "        \" performance in the few-shot setting. For all tasks, GPT-3 is applied\"\n",
    "        \" without any gradient updates or fine-tuning, with tasks and few-shot\"\n",
    "        \" demonstrations specified purely via text interaction with the model.\"\n",
    "        \" GPT-3 achieves strong performance on many NLP datasets, including\"\n",
    "        \" translation, question-answering, and cloze tasks, as well as several\"\n",
    "        \" tasks that require on-the-fly reasoning or domain adaptation, such as\"\n",
    "        \" unscrambling words, using a novel word in a sentence, or performing\"\n",
    "        \" 3-digit arithmetic. At the same time, we also identify some datasets\"\n",
    "        \" where GPT-3's few-shot learning still struggles, as well as some\"\n",
    "        \" datasets where GPT-3 faces methodological issues related to training\"\n",
    "        \" on large web corpora. Finally, we find that GPT-3 can generate\"\n",
    "        \" samples of news articles which human evaluators have difficulty\"\n",
    "        \" distinguishing from articles written by humans. We discuss broader\"\n",
    "        \" societal impacts of this finding and of GPT-3 in general.\"\n",
    "    ),\n",
    "    cite_as=(\n",
    "        \"@article{brown2020language, title={Language Models are Few-Shot\"\n",
    "        \" Learners}, author={Tom B. Brown and Benjamin Mann and Nick Ryder and\"\n",
    "        \" Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind\"\n",
    "        \" Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and\"\n",
    "        \" Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom\"\n",
    "        \" Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and\"\n",
    "        \" Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and\"\n",
    "        \" Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and\"\n",
    "        \" Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford\"\n",
    "        \" and Ilya Sutskever and Dario Amodei}, year={2020},\"\n",
    "        \" eprint={2005.14165}, archivePrefix={arXiv}, primaryClass={cs.CL} }\"\n",
    "    ),\n",
    "    url=\"https://github.com/AllenInstitute/GRNN\",\n",
    "    distribution=distribution,\n",
    "    record_sets=record_sets,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(metadata.issues.report())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"croissant.json\", \"w\") as f:\n",
    "  content = metadata.to_json()\n",
    "  content = json.dumps(content, indent=2)\n",
    "  #print(content)\n",
    "  f.write(content)\n",
    "  f.write(\"\\n\")  # Terminate file with newline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cell_id': 566517779, 'cre-line': b'Chrna2-Cre_OE25', 'bin_size': 10, 'actv_bin_size': 20, 'val_evr': 0.594774315578198, 'test_evr': 0.5847444417389941, 'train_loss': 0.152364676816367, 'test_loss': 0.037812300461989, 'a': 8.994219779968262}\n",
      "{'cell_id': 486875162, 'cre-line': b'Htr3a-Cre_NO152', 'bin_size': 10, 'actv_bin_size': 20, 'val_evr': 0.6407574082969301, 'test_evr': 0.648385856441786, 'train_loss': 0.114419631612205, 'test_loss': 0.101205808199368, 'a': 8.690719604492188}\n",
      "{'cell_id': 562651165, 'cre-line': b'Ndnf-IRES2-dgCre', 'bin_size': 10, 'actv_bin_size': 20, 'val_evr': 0.733286328159182, 'test_evr': 0.7744659475322031, 'train_loss': 0.079649135694039, 'test_loss': 0.11636616633488502, 'a': 8.911795616149902}\n",
      "{'cell_id': 608108585, 'cre-line': b'Tlx3-Cre_PL56', 'bin_size': 10, 'actv_bin_size': 20, 'val_evr': 0.575433351414624, 'test_evr': 0.5345231165651411, 'train_loss': 0.211468438777793, 'test_loss': 0.09044960608849101, 'a': 9.044020652770996}\n",
      "{'cell_id': 479993900, 'cre-line': b'Scnn1a-Tg2-Cre', 'bin_size': 10, 'actv_bin_size': 20, 'val_evr': 0.6301816029627121, 'test_evr': 0.6134543460343921, 'train_loss': 0.12570976743644802, 'test_loss': 0.07953336275540801, 'a': 9.006967544555664}\n",
      "{'cell_id': 569270348, 'cre-line': b'Ndnf-IRES2-dgCre', 'bin_size': 10, 'actv_bin_size': 20, 'val_evr': 0.874200901754637, 'test_evr': 0.8896725993438801, 'train_loss': 0.10844100310299601, 'test_loss': 0.17005042442908602, 'a': 9.190787315368652}\n",
      "{'cell_id': 609435731, 'cre-line': b'Slc32a1-T2A-FlpO|Vipr2-IRES2-Cre', 'bin_size': 10, 'actv_bin_size': 20, 'val_evr': 0.9108718308605711, 'test_evr': 0.8927042442705551, 'train_loss': 0.402688039217568, 'test_loss': 0.177894345797025, 'a': 9.00441837310791}\n",
      "{'cell_id': 485245025, 'cre-line': b'Pvalb-IRES-Cre', 'bin_size': 10, 'actv_bin_size': 20, 'val_evr': 0.9252158021698301, 'test_evr': 0.9011161074298351, 'train_loss': 0.12379439919226201, 'test_loss': 0.166529410226004, 'a': 8.937079429626465}\n",
      "{'cell_id': 476086391, 'cre-line': b'Nr5a1-Cre', 'bin_size': 10, 'actv_bin_size': 20, 'val_evr': 0.733562675566894, 'test_evr': 0.7836748926270141, 'train_loss': 0.08677696020695301, 'test_loss': 0.07024798466609, 'a': 9.1328125}\n",
      "{'cell_id': 486178939, 'cre-line': b'Rbp4-Cre_KL100', 'bin_size': 10, 'actv_bin_size': 20, 'val_evr': 0.5452879692297621, 'test_evr': 0.44394432496316105, 'train_loss': 0.08551771467003201, 'test_loss': 0.13203171950120102, 'a': 9.264827728271484}\n",
      "{'cell_id': 586072188, 'cre-line': b'Chat-IRES-Cre-neo', 'bin_size': 10, 'actv_bin_size': 20, 'val_evr': 0.638989422501901, 'test_evr': 0.6762394688584461, 'train_loss': 0.06695905220496601, 'test_loss': 0.09064836355356001, 'a': 8.982666969299316}\n",
      "{'cell_id': 475848827, 'cre-line': b'Rorb-IRES2-Cre', 'bin_size': 10, 'actv_bin_size': 20, 'val_evr': 0.523786538614416, 'test_evr': 0.59992244402988, 'train_loss': 0.07673458367185801, 'test_loss': 0.033498893150916004, 'a': 9.02536392211914}\n"
     ]
    }
   ],
   "source": [
    "dataset = mlc.Dataset(jsonld=\"croissant.json\")\n",
    "records = dataset.records(record_set=\"jsonl\")\n",
    "\n",
    "for i, record in enumerate(records):\n",
    "  print(record)\n",
    "  if i > 10:\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
