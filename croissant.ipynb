{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import mlcroissant as mlc\n",
    "\n",
    "use_jsonl = False\n",
    "\n",
    "# FileObjects and FileSets define the resources of the dataset.\n",
    "distribution = [\n",
    "    # GFR_Dataset is hosted on a GitHub repository:\n",
    "    mlc.FileObject(\n",
    "        id=\"github-repository\",\n",
    "        name=\"github-repository\",\n",
    "        description=\"Generalized Firing Rate Neurons repository on GitHub.\",\n",
    "        content_url=\"https://github.com/AllenInstitute/GRNN\",\n",
    "        encoding_format=\"git+https\",\n",
    "        sha256=\"main\",\n",
    "    ),\n",
    "    # Within that repository, a FileSet lists all JSONL files:\n",
    "    mlc.FileObject(\n",
    "        id=\"gfr_dataset.json\",\n",
    "        name=\"gfr_dataset.json\",\n",
    "        description=\"JSON hosted on the GitHub repository.\",\n",
    "        content_url=\"model/gfr_dataset.json\",\n",
    "        contained_in=[\"github-repository\"],\n",
    "        encoding_format=\"application/json\"\n",
    "    ),\n",
    "]\n",
    "record_sets = [\n",
    "    # RecordSets contains records in the dataset.\n",
    "    mlc.RecordSet(\n",
    "        id=\"dataset\",\n",
    "        name=\"dataset\",\n",
    "        # Each record has one or many fields...\n",
    "        fields=[\n",
    "            # Fields can be extracted from the FileObjects/FileSets.\n",
    "            mlc.Field(\n",
    "                id=\"dataset/cell_id\",\n",
    "                name=\"cell_id\",\n",
    "                description=\"Cell id of the cell.\",\n",
    "                data_types=mlc.DataType.INTEGER,\n",
    "                source=mlc.Source(\n",
    "                    file_set=\"gfr_dataset.json\",\n",
    "                    # extract=mlc.Extract(column=\"cell_id\"),\n",
    "                    # extract=mlc.Extract(json_path=\"x['cell_id']\"),\n",
    "                ),\n",
    "            ),\n",
    "            mlc.Field(\n",
    "                id=\"dataset/cre-line\",\n",
    "                name=\"cre-line\",\n",
    "                description=\"Cre-line of the cell.\",\n",
    "                data_types=mlc.DataType.TEXT,\n",
    "                source=mlc.Source(\n",
    "                    file_set=\"gfr_dataset.json\",\n",
    "                    extract=mlc.Extract(column=\"cre-line\"),\n",
    "                ),\n",
    "            ),\n",
    "            mlc.Field(\n",
    "                id=\"dataset/bin_size\",\n",
    "                name=\"bin_size\",\n",
    "                description=(\n",
    "                    \"Bin size.\"\n",
    "                ),\n",
    "                data_types=mlc.DataType.INTEGER,\n",
    "                source=mlc.Source(\n",
    "                    file_set=\"gfr_dataset.json\",\n",
    "                    extract=mlc.Extract(column=\"bin_size\"),\n",
    "                ),\n",
    "            ),\n",
    "            mlc.Field(\n",
    "                id=\"dataset/actv_bin_size\",\n",
    "                name=\"actv_bin_size\",\n",
    "                description=(\n",
    "                    \"Activation bin size.\"\n",
    "                ),\n",
    "                data_types=mlc.DataType.INTEGER,\n",
    "                source=mlc.Source(\n",
    "                    file_set=\"gfr_dataset.json\",\n",
    "                    extract=mlc.Extract(column=\"actv_bin_size\"),\n",
    "                ),\n",
    "            ),\n",
    "            mlc.Field(\n",
    "                id=\"dataset/val_evr\",\n",
    "                name=\"val_evr\",\n",
    "                description=(\n",
    "                    \"Explained variance ratio of the GFR model on the validation dataset.\"\n",
    "                ),\n",
    "                data_types=mlc.DataType.FLOAT,\n",
    "                source=mlc.Source(\n",
    "                    file_set=\"gfr_dataset.json\",\n",
    "                    extract=mlc.Extract(column=\"val_evr\"),\n",
    "                ),\n",
    "            ),\n",
    "            mlc.Field(\n",
    "                id=\"dataset/test_evr\",\n",
    "                name=\"test_evr\",\n",
    "                description=(\n",
    "                    \"Explained variance ratio of the GFR model on the test dataset.\"\n",
    "                ),\n",
    "                data_types=mlc.DataType.FLOAT,\n",
    "                source=mlc.Source(\n",
    "                    file_set=\"gfr_dataset.json\",\n",
    "                    extract=mlc.Extract(column=\"test_evr\"),\n",
    "                ),\n",
    "            ),\n",
    "            mlc.Field(\n",
    "                id=\"dataset/train_loss\",\n",
    "                name=\"train_loss\",\n",
    "                description=(\n",
    "                    \"Train loss of the GFR model.\"\n",
    "                ),\n",
    "                data_types=mlc.DataType.FLOAT,\n",
    "                source=mlc.Source(\n",
    "                    file_set=\"gfr_dataset.json\",\n",
    "                    extract=mlc.Extract(column=\"train_loss\"),\n",
    "                ),\n",
    "            ),\n",
    "            mlc.Field(\n",
    "                id=\"dataset/test_loss\",\n",
    "                name=\"test_loss\",\n",
    "                description=(\n",
    "                    \"Test loss of the GFR model.\"\n",
    "                ),\n",
    "                data_types=mlc.DataType.FLOAT,\n",
    "                source=mlc.Source(\n",
    "                    file_set=\"gfr_dataset.json\",\n",
    "                    extract=mlc.Extract(column=\"test_loss\"),\n",
    "                ),\n",
    "            ),\n",
    "            mlc.Field(\n",
    "                id=\"dataset/params\",\n",
    "                name=\"params\",\n",
    "                description=(\n",
    "                    \"Model parameters.\"\n",
    "                ),\n",
    "                sub_fields = [\n",
    "                    mlc.Field(\n",
    "                        id=\"dataset/params/a\",\n",
    "                        name=\"a\",\n",
    "                        description=\"Input current history kernel parameters.\",\n",
    "                        data_types=mlc.DataType.FLOAT,\n",
    "                        repeated=True,\n",
    "                        source=mlc.Source(\n",
    "                            file_set=\"gfr_dataset.json\",\n",
    "                            # extract=mlc.Extract(json_path=\"x['params']['a']\"),\n",
    "                            # extract=mlc.Extract(column=\"params\"),\n",
    "                            # transforms=[mlc.Transform(json_path=\"a[0][0]\")], # MUSTFIX : this is not working\n",
    "                        ),\n",
    "                    ),\n",
    "                    mlc.Field(\n",
    "                        id=\"dataset/params/b\",\n",
    "                        name=\"b\",\n",
    "                        description=\"Firing rate history kernel parameters.\",\n",
    "                        data_types=mlc.DataType.FLOAT,\n",
    "                        repeated=True,\n",
    "                        source=mlc.Source(\n",
    "                            file_set=\"gfr_dataset.json\",\n",
    "                            # extract=mlc.Extract(json_path=\"x['params']['b']\"),\n",
    "                            # extract=mlc.Extract(column=\"params\"),\n",
    "                            # transforms=[mlc.Transform(json_path=\"b[0][0]\")], # MUSTFIX : this is not working\n",
    "                        ),\n",
    "                    ),\n",
    "                    mlc.Field(\n",
    "                        id=\"dataset/params/ds\",\n",
    "                        name=\"ds\",\n",
    "                        description=\"Decay coefficients.\",\n",
    "                        data_types=mlc.DataType.FLOAT,\n",
    "                        repeated=True,\n",
    "                        source=mlc.Source(\n",
    "                            file_set=\"gfr_dataset.json\",\n",
    "                            # extract=mlc.Extract(json_path=\"x['params']['ds']\"),\n",
    "                            # extract=mlc.Extract(column=\"params\"),\n",
    "                            # transforms=[mlc.Transform(json_path=\"ds[0]\")], # MUSTFIX : this is not working\n",
    "                        ),\n",
    "                    ),\n",
    "                    mlc.Field(\n",
    "                        id=\"dataset/params/bin_size\",\n",
    "                        name=\"params_bin_size\",\n",
    "                        description=\"Bin size of the GFR model.\",\n",
    "                        data_types=mlc.DataType.INTEGER,\n",
    "                        repeated=True,\n",
    "                        source=mlc.Source(\n",
    "                            file_set=\"gfr_dataset.json\",\n",
    "                            # extract=mlc.Extract(json_path=\"x['params']['bin_size']\"),\n",
    "                            # extract=mlc.Extract(column=\"params\"),\n",
    "                            # transforms=[mlc.Transform(json_path=\"bin_size\")], # MUSTFIX : this is not working\n",
    "                        ),\n",
    "                    ),\n",
    "                    mlc.Field(\n",
    "                        id=\"dataset/params/g\",\n",
    "                        name=\"params_g\",\n",
    "                        description=\"Activation function.\",\n",
    "                        data_types=mlc.DataType.FLOAT,\n",
    "                        repeated=True,\n",
    "                        source=mlc.Source(\n",
    "                            file_set=\"gfr_dataset.json\",\n",
    "                            # extract=mlc.Extract(json_path=\"x['params']['g']\"),\n",
    "                            # extract=mlc.Extract(column=\"params\"),\n",
    "                            # transforms=[mlc.Transform(json_path=\"g\")],\n",
    "                        ),\n",
    "                        sub_fields = [\n",
    "                            mlc.Field(\n",
    "                                id=\"dataset/params/g/max_current\",\n",
    "                                name=\"max_current\",\n",
    "                                description=\"Maximum current.\",\n",
    "                                data_types=mlc.DataType.FLOAT,\n",
    "                                repeated=True,\n",
    "                                source=mlc.Source(\n",
    "                                    # extract=mlc.Extract(json_path=\"x['params']['g']['max_current']\")\n",
    "                                    # extract=mlc.Extract(column=\"params\"),\n",
    "                                    # transforms=[mlc.Transform(json_path=\"params.g.max_current\")],\n",
    "                                ),\n",
    "                            ),\n",
    "                            mlc.Field(\n",
    "                                id=\"dataset/params/g/max_firing_rate\",\n",
    "                                name=\"max_firing_rate\",\n",
    "                                description=\"Maximum firing rate.\",\n",
    "                                data_types=mlc.DataType.FLOAT,\n",
    "                                repeated=True,\n",
    "                                source=mlc.Source(\n",
    "                                    file_set=\"gfr_dataset.json\",\n",
    "                                    # extract=mlc.Extract(json_path=\"x['params']['g']['max_firing_rate']\")\n",
    "                                    # extract=mlc.Extract(column=\"params\"),\n",
    "                                    # transforms=[mlc.Transform(json_path=\"g.max_firing_rate\")],\n",
    "                                ),\n",
    "                            ),\n",
    "                            mlc.Field(\n",
    "                                id=\"dataset/params/g/poly_coeff\",\n",
    "                                name=\"poly_coeff\",\n",
    "                                description=\"Polynomial coefficients of the activation function.\",\n",
    "                                data_types=mlc.DataType.FLOAT,\n",
    "                                repeated=True,\n",
    "                                source=mlc.Source(\n",
    "                                    file_set=\"gfr_dataset.json\",\n",
    "                                    # extract=mlc.Extract(json_path=\"x['params']['g']['poly_coeff']\")\n",
    "                                    # extract=mlc.Extract(column=\"params\"),\n",
    "                                    # transforms=[mlc.Transform(json_path=\"g.poly_coeff\")],\n",
    "                                ),\n",
    "                            ),\n",
    "                            mlc.Field(\n",
    "                                id=\"dataset/params/g/b\",\n",
    "                                name=\"g_b\",\n",
    "                                description=\"Firing threshold of the activation function.\",\n",
    "                                data_types=mlc.DataType.FLOAT,\n",
    "                                repeated=True,\n",
    "                                source=mlc.Source(\n",
    "                                    file_set=\"gfr_dataset.json\",\n",
    "                                    # extract=mlc.Extract(json_path=\"x['params']['g']['b']\")\n",
    "                                    # extract=mlc.Extract(column=\"params\"),\n",
    "                                    # transforms=[mlc.Transform(json_path=\"g.b\")],\n",
    "                                ),\n",
    "                            ),\n",
    "                            mlc.Field(\n",
    "                                id=\"dataset/params/g/bin_size\",\n",
    "                                name=\"g_bin_size\",\n",
    "                                description=\"Bin size of the activation function.\",\n",
    "                                data_types=mlc.DataType.INTEGER,\n",
    "                                repeated=True,\n",
    "                                source=mlc.Source(\n",
    "                                    file_set=\"gfr_dataset.json\",\n",
    "                                    # extract=mlc.Extract(json_path=\"x['params']['g']['bin_size']\")\n",
    "                                    # extract=mlc.Extract(column=\"params\"),\n",
    "                                    # transforms=[mlc.Transform(json_path=\"g.bin_size\")],\n",
    "                                ),\n",
    "                            ),\n",
    "                        ]\n",
    "                    ),\n",
    "                ],\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "]\n",
    "\n",
    "# Metadata contains information about the dataset.\n",
    "metadata = mlc.Metadata(\n",
    "    name=\"GFR_Dataset\",\n",
    "    # Descriptions can contain plain text or markdown.\n",
    "    description=(\n",
    "        \"A dataset of over 1000 biologically-derived, parameterized, and differentiable neuronal models.\"\n",
    "    ),\n",
    "    cite_as=(\n",
    "        \"@article{gfr2024, title={A dataset of differentiable biologically-derived single neuron models}, \"\n",
    "        \" author={Anonymous}, year={2024},\"\n",
    "        \" eprint={2024.0000}, archivePrefix={arXiv}, primaryClass={cs.CL} }\"\n",
    "    ),\n",
    "    url=\"https://github.com/Anonymous/GRNN\",\n",
    "    license=\"https://creativecommons.org/licenses/by/4.0/\",\n",
    "    version=\"1.0.0\",\n",
    "    distribution=distribution,\n",
    "    #record_sets=record_sets,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(metadata.issues.report())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"croissant.json\", \"w\") as f:\n",
    "  content = metadata.to_json()\n",
    "  content = json.dumps(content, indent=2)\n",
    "  #print(content)\n",
    "  f.write(content)\n",
    "  f.write(\"\\n\")  # Terminate file with newline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "ename": "GenerationError",
     "evalue": "An error occured during the streaming generation of the dataset, more specifically during the operation Read(jsonl-files)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mlcroissant/_src/operation_graph/execute.py:97\u001b[0m, in \u001b[0;36mexecute_operations_in_streaming\u001b[0;34m(record_set, operations, list_of_operations, result)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m operation(result)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mlcroissant/_src/operation_graph/operations/field.py:184\u001b[0m, in \u001b[0;36mReadFields.__call__\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df), chunk_size):\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_get_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9559\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m   9560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9561\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9566\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   9567\u001b[0m )\n\u001b[0;32m-> 9568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 891\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 907\u001b[0m     results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    909\u001b[0m         \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mlcroissant/_src/operation_graph/operations/field.py:172\u001b[0m, in \u001b[0;36mReadFields.__call__.<locals>._get_result\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m    171\u001b[0m column \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mget_column()\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m df, (\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m does not exist. Inspect the ancestors of the\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m field \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfield\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to understand why. Possible fields: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m )\n\u001b[1;32m    176\u001b[0m value \u001b[38;5;241m=\u001b[39m row[column]\n",
      "\u001b[0;31mAssertionError\u001b[0m: Column \"x['cell_id']\" does not exist. Inspect the ancestors of the field Field(uuid=\"jsonl/cell_id\") to understand why. Possible fields: Index([            'cell_id',            'cre-line',            'bin_size',\n             'actv_bin_size',             'val_evr',            'test_evr',\n                'train_loss',           'test_loss',              'params',\n       FileProperty.filepath, FileProperty.filename, FileProperty.fullpath],\n      dtype='object')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mGenerationError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mlcroissant/_src/operation_graph/execute.py:115\u001b[0m, in \u001b[0;36mexecute_operations_in_streaming\u001b[0;34m(record_set, operations, list_of_operations, result)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m execute_operations_in_streaming(\n\u001b[1;32m    109\u001b[0m             record_set\u001b[38;5;241m=\u001b[39mrecord_set,\n\u001b[1;32m    110\u001b[0m             operations\u001b[38;5;241m=\u001b[39moperations,\n\u001b[1;32m    111\u001b[0m             list_of_operations\u001b[38;5;241m=\u001b[39mlist_of_operations[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m :],\n\u001b[1;32m    112\u001b[0m             result\u001b[38;5;241m=\u001b[39moperation(file),\n\u001b[1;32m    113\u001b[0m         )\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m read_all_files()\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mlcroissant/_src/operation_graph/execute.py:108\u001b[0m, in \u001b[0;36mexecute_operations_in_streaming.<locals>.read_all_files\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuting \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, operation)\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m execute_operations_in_streaming(\n\u001b[1;32m    109\u001b[0m     record_set\u001b[38;5;241m=\u001b[39mrecord_set,\n\u001b[1;32m    110\u001b[0m     operations\u001b[38;5;241m=\u001b[39moperations,\n\u001b[1;32m    111\u001b[0m     list_of_operations\u001b[38;5;241m=\u001b[39mlist_of_operations[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m :],\n\u001b[1;32m    112\u001b[0m     result\u001b[38;5;241m=\u001b[39moperation(file),\n\u001b[1;32m    113\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mlcroissant/_src/operation_graph/execute.py:123\u001b[0m, in \u001b[0;36mexecute_operations_in_streaming\u001b[0;34m(record_set, operations, list_of_operations, result)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GenerationError(\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occured during the streaming generation of the dataset, more\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m specifically during the operation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moperation\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mGenerationError\u001b[0m: An error occured during the streaming generation of the dataset, more specifically during the operation ReadFields(jsonl)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mGenerationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[217], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m mlc\u001b[38;5;241m.\u001b[39mDataset(jsonld\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcroissant.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m records \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mrecords(record_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, record \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(records):\n\u001b[1;32m      5\u001b[0m   \u001b[38;5;28mprint\u001b[39m(record)\n\u001b[1;32m      6\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m10\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mlcroissant/_src/datasets.py:135\u001b[0m, in \u001b[0;36mRecords.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m can_stream_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m(d \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m d \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, d \u001b[38;5;129;01min\u001b[39;00m operations\u001b[38;5;241m.\u001b[39mdegree())\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_stream_dataset:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m execute_operations_in_streaming(\n\u001b[1;32m    136\u001b[0m         record_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord_set,\n\u001b[1;32m    137\u001b[0m         operations\u001b[38;5;241m=\u001b[39moperations,\n\u001b[1;32m    138\u001b[0m     )\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m execute_operations_sequentially(\n\u001b[1;32m    141\u001b[0m         record_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord_set, operations\u001b[38;5;241m=\u001b[39moperations\n\u001b[1;32m    142\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mlcroissant/_src/operation_graph/execute.py:123\u001b[0m, in \u001b[0;36mexecute_operations_in_streaming\u001b[0;34m(record_set, operations, list_of_operations, result)\u001b[0m\n\u001b[1;32m    121\u001b[0m         result \u001b[38;5;241m=\u001b[39m operation(result)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GenerationError(\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occured during the streaming generation of the dataset, more\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m specifically during the operation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moperation\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mGenerationError\u001b[0m: An error occured during the streaming generation of the dataset, more specifically during the operation Read(jsonl-files)"
     ]
    }
   ],
   "source": [
    "dataset = mlc.Dataset(jsonld=\"croissant.json\")\n",
    "records = dataset.records(record_set=\"jsonl\")\n",
    "\n",
    "for i, record in enumerate(records):\n",
    "  print(record)\n",
    "  if i > 10:\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
