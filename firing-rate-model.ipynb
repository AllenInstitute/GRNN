{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55504ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.utils\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model import FiringRateModel, PolynomialActivation\n",
    "from train import train_model\n",
    "from data import get_data, get_train_test_data\n",
    "from evaluate import explained_variance_ratio\n",
    "from utils import plot_predictions, plot_kernel\n",
    "from config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5bc1fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59b775ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    Is, \n",
    "    fs, \n",
    "    g,\n",
    "    ds,\n",
    "    cell_id, \n",
    "    bin_size,  \n",
    "    device = None,\n",
    "    hparams=[{\"lr\": 0.03, \"gamma\": 0.85, \"step_size\": 5, \"epochs\": 100}]\n",
    "):\n",
    "    best_model, best_losses = None, [0, 1e10]\n",
    "    \n",
    "    for i, hs in enumerate(hparams):\n",
    "        print(f\"Run {i}: {hs}\")\n",
    "        model = FiringRateModel(\n",
    "            g.to(device), ds, bin_size=bin_size, device=device\n",
    "        ).to(device)\n",
    "\n",
    "        criterion = torch.nn.PoissonNLLLoss(log_input=False, reduction=\"none\")\n",
    "        optimizer = torch.optim.RMSprop(model.parameters(), lr=hs[\"lr\"], centered=True)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=hs[\"gamma\"], step_size=hs[\"step_size\"])\n",
    "\n",
    "        losses = train_model(\n",
    "            model, \n",
    "            criterion, \n",
    "            optimizer,\n",
    "            Is,\n",
    "            fs,\n",
    "            epochs = hs[\"epochs\"],\n",
    "            print_every = 1,\n",
    "            bin_size = bin_size,\n",
    "            up_factor = 1,\n",
    "            scheduler = scheduler\n",
    "        )\n",
    "        \n",
    "        if best_losses[-1] > losses[-1]:\n",
    "            best_losses = losses\n",
    "            best_model = model\n",
    "    \n",
    "    return best_model, best_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51bdf93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476129135\n",
      "Error\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'params' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m Is_tr, fs_tr, stims \u001b[38;5;241m=\u001b[39m sklearn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mshuffle(Is_tr, fs_tr, stims)\n\u001b[1;32m     19\u001b[0m actv \u001b[38;5;241m=\u001b[39m PolynomialActivation()\n\u001b[0;32m---> 20\u001b[0m \u001b[43mactv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel/activation/poisson/bin_size_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mactv_bin_size\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcell_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_0.pickle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m model, losses \u001b[38;5;241m=\u001b[39m train(Is_tr, fs_tr, actv, ds, cell_id, bin_size, device\u001b[38;5;241m=\u001b[39mdevice, hparams\u001b[38;5;241m=\u001b[39mhparams)\n\u001b[1;32m     23\u001b[0m d[cell_id] \u001b[38;5;241m=\u001b[39m (model, losses)\n",
      "File \u001b[0;32m~/Documents/GitHub/GRNN/model.py:118\u001b[0m, in \u001b[0;36mPolynomialActivation.init_from_file\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_from_params(\u001b[43mparams\u001b[49m)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'params' referenced before assignment"
     ]
    }
   ],
   "source": [
    "d = {}\n",
    "\n",
    "bin_size = 20\n",
    "ds = np.linspace(0.05, 1.0, 20)\n",
    "actv_bin_size = 20\n",
    "\n",
    "hparams = [\n",
    "    {\"lr\": 0.03, \"gamma\": 0.85, \"step_size\": 5, \"epochs\": 150},\n",
    "    {\"lr\": 0.02, \"gamma\": 0.90, \"step_size\": 10, \"epochs\": 200},\n",
    "    {\"lr\": 0.01, \"gamma\": 0.95, \"step_size\": 20, \"epochs\": 250}\n",
    "]\n",
    "\n",
    "for cell_id in [476129135]:\n",
    "    print(cell_id)\n",
    "    data = get_data(cell_id, aligned=True)\n",
    "    Is_tr, fs_tr, Is_te, fs_te, stims = get_train_test_data(data, bin_size, device=device)\n",
    "    Is_tr, fs_tr, stims = sklearn.utils.shuffle(Is_tr, fs_tr, stims)\n",
    "\n",
    "    actv = PolynomialActivation()\n",
    "    actv.init_from_file(f\"model/activation/poisson/bin_size_{actv_bin_size}/{cell_id}_0.pickle\")\n",
    "    model, losses = train(Is_tr, fs_tr, actv, ds, cell_id, bin_size, device=device, hparams=hparams)\n",
    "    \n",
    "    d[cell_id] = (model, losses)\n",
    "    \n",
    "    save = False\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    if save:\n",
    "        plt.savefig(config[\"fig_save_path\"] + f\"{cell_id}/bin_size_{bin_size}/Loss_{actv_bin_size}.png\")\n",
    "        plt.close()\n",
    "\n",
    "    for Is, fs, s in zip(Is_tr, fs_tr, stims):\n",
    "        for i in range(Is.shape[0]):\n",
    "            plot_predictions(\n",
    "                model, \n",
    "                Is[i, :], \n",
    "                fs[i, :], \n",
    "                cell_id, \n",
    "                bin_size, \n",
    "                evr = None,\n",
    "                save = save,\n",
    "                fname = f\"{s} {i}_{actv_bin_size}\"\n",
    "            )\n",
    "\n",
    "    r = explained_variance_ratio(model, Is_te[0], fs_te[0], bin_size)\n",
    "    rq = explained_variance_ratio(model, Is_te[0], fs_te[0], bin_size, quantize=True)\n",
    "    plot_predictions(\n",
    "        model, \n",
    "        Is_te[0][0, :], \n",
    "        fs_te[0][0, :], \n",
    "        cell_id, \n",
    "        bin_size, \n",
    "        evr = (r, rq),\n",
    "        save = save,\n",
    "        fname = f\"Noise 2_{actv_bin_size}\"\n",
    "    )\n",
    "\n",
    "    plot_kernel(\n",
    "        model,\n",
    "        cell_id,\n",
    "        bin_size,\n",
    "        save = save,\n",
    "        fname = f\"Kernel_{actv_bin_size}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d496f826",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "for fname in os.listdir(\"model/params\"):\n",
    "    with open(f\"model/params/{fname}\", \"rb\") as f:\n",
    "        p = pickle.load(f)\n",
    "        params[int(fname.split(\".\")[0])] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddf391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = 0\n",
    "low_evr = []\n",
    "for cell_id in params:\n",
    "    evr = params[cell_id][\"evr\"]\n",
    "    losses = params[cell_id][\"losses\"]\n",
    "    print(cell_id, evr, losses[-1], len(losses))\n",
    "    if evr == 0:\n",
    "        zeros += 1\n",
    "    if evr < 0.4 or losses[-1] > 1000:\n",
    "        low_evr.append(cell_id)\n",
    "print(zeros, len(params), zeros / len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff157955",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(low_evr))\n",
    "with open(\"misc/cell_ids_rerun.csv\", \"w\") as f:\n",
    "    f.write(\",\".join(map(str, low_evr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2ede08",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model/max_firing_rates.pickle\", \"rb\") as f:\n",
    "    a = pickle.load(f)\n",
    "    \n",
    "#with open(\"misc/cell_ids_mfr.csv\", \"w\") as f:\n",
    "#    f.write(\",\".join(map(str, a.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01296bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3308e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
