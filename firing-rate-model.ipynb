{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55504ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.utils\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model import FiringRateModel, PolynomialActivation\n",
    "from train import train_model\n",
    "from data import get_data, get_train_test_data\n",
    "from evaluate import explained_variance_ratio\n",
    "from utils import plot_predictions, plot_kernel\n",
    "from config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5bc1fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59b775ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    Is, \n",
    "    fs, \n",
    "    g,\n",
    "    ds,\n",
    "    cell_id, \n",
    "    bin_size,  \n",
    "    device = None,\n",
    "    hparams=[{\"lr\": 0.03, \"gamma\": 0.85, \"step_size\": 5, \"epochs\": 100}]\n",
    "):\n",
    "    best_model, best_losses = None, [0, 1e10]\n",
    "    \n",
    "    for i, hs in enumerate(hparams):\n",
    "        print(f\"Run {i}: {hs}\")\n",
    "        model = FiringRateModel(\n",
    "            g.to(device), ds, bin_size=bin_size, device=device\n",
    "        ).to(device)\n",
    "\n",
    "        criterion = torch.nn.PoissonNLLLoss(log_input=False, reduction=\"none\")\n",
    "        optimizer = torch.optim.RMSprop(model.parameters(), lr=hs[\"lr\"], centered=True)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=hs[\"gamma\"], step_size=hs[\"step_size\"])\n",
    "\n",
    "        losses = train_model(\n",
    "            model, \n",
    "            criterion, \n",
    "            optimizer,\n",
    "            Is,\n",
    "            fs,\n",
    "            epochs = hs[\"epochs\"],\n",
    "            print_every = 1,\n",
    "            bin_size = bin_size,\n",
    "            up_factor = 1,\n",
    "            scheduler = scheduler\n",
    "        )\n",
    "        \n",
    "        if best_losses[-1] > losses[-1]:\n",
    "            best_losses = losses\n",
    "            best_model = model\n",
    "    \n",
    "    return best_model, best_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51bdf93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504615116\n",
      "Run 0: {'lr': 0.03, 'gamma': 0.85, 'step_size': 5, 'epochs': 100}\n",
      "Epoch 1 / Loss: 2520.3918194770813 / lr: [0.03]\n",
      "Epoch 2 / Loss: 987.1531491279602 / lr: [0.03]\n",
      "Epoch 3 / Loss: 971.3938717842102 / lr: [0.03]\n",
      "Epoch 4 / Loss: 969.5982899665833 / lr: [0.03]\n",
      "Epoch 5 / Loss: 999.4901089668274 / lr: [0.0255]\n",
      "Epoch 6 / Loss: 1039.0698475837708 / lr: [0.0255]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m actv \u001b[38;5;241m=\u001b[39m PolynomialActivation()\n\u001b[1;32m     19\u001b[0m actv\u001b[38;5;241m.\u001b[39minit_from_file(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel/activation/poisson/bin_size_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactv_bin_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcell_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_0.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m model, losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mIs_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbin_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m d[cell_id] \u001b[38;5;241m=\u001b[39m (model, losses)\n\u001b[1;32m     24\u001b[0m save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[28], line 28\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(Is, fs, g, cell_id, bin_size, ds, device, plot, hparams)\u001b[0m\n\u001b[1;32m     25\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mRMSprop(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mhs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m], centered\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     26\u001b[0m     scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(optimizer, gamma\u001b[38;5;241m=\u001b[39mhs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m\"\u001b[39m], step_size\u001b[38;5;241m=\u001b[39mhs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep_size\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 28\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mIs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbin_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbin_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mup_factor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m plot:\n\u001b[1;32m     42\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(losses))), losses)\n",
      "File \u001b[0;32m~/Documents/GitHub/GRNN/train.py:37\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, Is_tr, fs_tr, epochs, print_every, bin_size, up_factor, scheduler)\u001b[0m\n\u001b[1;32m     35\u001b[0m mean_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(loss)\n\u001b[1;32m     36\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 37\u001b[0m \u001b[43mmean_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     39\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m mean_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "d = {}\n",
    "\n",
    "bin_size = 20\n",
    "ds = np.linspace(0.05, 1.0, 20)\n",
    "actv_bin_size = 20\n",
    "\n",
    "hparams = [\n",
    "    {\"lr\": 0.03, \"gamma\": 0.85, \"step_size\": 5, \"epochs\": 150},\n",
    "    {\"lr\": 0.02, \"gamma\": 0.90, \"step_size\": 10, \"epochs\": 200},\n",
    "    {\"lr\": 0.01, \"gamma\": 0.95, \"step_size\": 20, \"epochs\": 250}\n",
    "]\n",
    "\n",
    "for cell_id in [504615116]:\n",
    "    print(cell_id)\n",
    "    data = get_data(cell_id, aligned=False)\n",
    "    Is_tr, fs_tr, Is_te, fs_te, stims = get_train_test_data(data, bin_size, device=device)\n",
    "    Is_tr, fs_tr, stims = sklearn.utils.shuffle(Is_tr, fs_tr, stims)\n",
    "\n",
    "    actv = PolynomialActivation()\n",
    "    actv.init_from_file(f\"model/activation/poisson/bin_size_{actv_bin_size}/{cell_id}_0.pickle\")\n",
    "    model, losses = train(Is_tr, fs_tr, actv, ds, cell_id, bin_size, device=device, hparams=hparams)\n",
    "    \n",
    "    d[cell_id] = (model, losses)\n",
    "    \n",
    "    save = False\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    if save:\n",
    "        plt.savefig(config[\"fig_save_path\"] + f\"{cell_id}/bin_size_{bin_size}/Loss_{actv_bin_size}.png\")\n",
    "        plt.close()\n",
    "\n",
    "    for Is, fs, s in zip(Is_tr, fs_tr, stims):\n",
    "        for i in range(Is.shape[0]):\n",
    "            plot_predictions(\n",
    "                model, \n",
    "                Is[i, :], \n",
    "                fs[i, :], \n",
    "                cell_id, \n",
    "                bin_size, \n",
    "                evr = None,\n",
    "                save = save,\n",
    "                fname = f\"{s} {i}_{actv_bin_size}\"\n",
    "            )\n",
    "\n",
    "    r = explained_variance_ratio(model, Is_te[0], fs_te[0], bin_size)\n",
    "    rq = explained_variance_ratio(model, Is_te[0], fs_te[0], bin_size, quantize=True)\n",
    "    plot_predictions(\n",
    "        model, \n",
    "        Is_te[0][0, :], \n",
    "        fs_te[0][0, :], \n",
    "        cell_id, \n",
    "        bin_size, \n",
    "        evr = (r, rq),\n",
    "        save = save,\n",
    "        fname = f\"Noise 2_{actv_bin_size}\"\n",
    "    )\n",
    "\n",
    "    plot_kernel(\n",
    "        model,\n",
    "        cell_id,\n",
    "        bin_size,\n",
    "        save = save,\n",
    "        fname = f\"Kernel_{actv_bin_size}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdff9b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "for fname in os.listdir(\"model/params\"):\n",
    "    with open(f\"model/params/{fname}\", \"rb\") as f:\n",
    "        p = pickle.load(f)\n",
    "        params[int(fname.split(\".\")[0])] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9938ce02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486108147 0.0 1861.5973682403564 3\n",
      "519549081 0.6787225463498096 811.0293779373169 100\n",
      "557673526 0.0 1218.5665192604065 5\n",
      "598631490 0.5721024572341907 318.5241174697876 100\n",
      "471789504 0.5330148182587963 453.4574975967407 100\n",
      "482764620 0.5335841474131224 328.4434537887573 100\n",
      "485905411 0.6699781445565169 1019.4499855041504 100\n",
      "586071425 0.4290628297049154 583.0667514801025 100\n",
      "605141937 0.0 529.122296333313 5\n",
      "563373346 0.0 1596.1170492172241 4\n",
      "395785266 0.0 684.7365574836731 3\n",
      "560581448 0.0 1975.8529114723206 3\n",
      "320836481 0.0 1181.9007959365845 3\n",
      "471129934 0.0 2441.14665555954 3\n",
      "539742766 0.518410366612419 522.0424337387085 100\n",
      "562999984 0.0 1845.497854232788 3\n",
      "341459814 0.6156119068189461 9183.384977340698 12\n",
      "329224678 0.7957456277904075 1484.7973337173462 100\n",
      "489888847 0.6701653157776143 197.70465850830078 100\n",
      "555089724 0.8309889370779364 276.5547876358032 100\n",
      "502647640 0.6434409456659594 781.1866598129272 15\n",
      "557261437 0.6720896931664071 261.7853980064392 100\n",
      "314800921 0.6401805990487401 715.4310131072998 100\n",
      "578938153 0.49957652188351154 639.7264633178711 100\n",
      "599177740 0.0 933.5707321166992 14\n",
      "554432769 0.7404783319347084 247.0332899093628 100\n",
      "476104386 0.9432711165044799 1572.4163694381714 100\n",
      "563338541 0.32733789936780977 298.7323246002197 100\n",
      "569664731 0.46565624439171865 221.77945804595947 100\n",
      "587064346 0.7989886963317837 265.89038276672363 100\n",
      "502260112 0.6976191958699028 456.5564675331116 100\n",
      "580145037 0.920693445361513 1067.4996590614319 100\n",
      "485468180 0.1640002903672876 497.19795179367065 100\n",
      "565866518 0.945785259932097 499.1468448638916 100\n",
      "519220630 0.6889208836123466 877.5481853485107 100\n",
      "572609644 0.6097602411875728 381.09658002853394 100\n",
      "478058328 0.9385745173051045 1315.2228174209595 100\n",
      "486756093 0.5186630990825475 493.46466064453125 100\n",
      "561533860 0.7478046395811234 234.5795660018921 100\n",
      "491038812 0.9349021653935833 327.80197620391846 100\n",
      "570280138 0.0 1403.1196546554565 5\n",
      "478586425 0.8624791998491653 879.5966329574585 100\n",
      "580537822 0.6277453217538544 2189.611156463623 100\n",
      "569730838 0.5005745603093107 340.93526458740234 100\n",
      "522723828 0.6230009542000721 499.66370248794556 100\n",
      "593398067 0.6542397710296233 141.1110544204712 100\n",
      "500879695 0.0 15615.927985191345 7\n",
      "588711875 0.6065927920551873 227.91902256011963 100\n",
      "488708322 0.0 6788.526326179504 5\n",
      "623427407 0.39485679868042944 591.3487520217896 100\n",
      "475580568 0.9012150380668391 1078.3528451919556 100\n",
      "560965993 0.7436874981895331 334.63798332214355 100\n",
      "592819166 0.8601275552780837 411.50439262390137 100\n",
      "589442285 0.617687638955276 204.36293840408325 100\n",
      "486111903 0.6044860930751165 1628.7553944587708 100\n",
      "588699048 0.7934549046675291 426.8983082771301 100\n",
      "479150681 0.7403342374621074 234.36154556274414 100\n",
      "586517633 0.38376452601367605 249.06441116333008 100\n",
      "327566447 0.7137846224909262 940.5736818313599 100\n",
      "479766169 0.6923965672399869 330.2999749183655 100\n",
      "568757860 0.6457010419288952 241.8498420715332 100\n",
      "585947309 0.0 7488.257948875427 4\n",
      "322197160 0.0 7229.142880439758 8\n",
      "606245618 0.7201953684481675 276.1098051071167 100\n",
      "605660220 0.5840286592389942 247.09299564361572 100\n",
      "515511110 0.5508511096463254 270.0556445121765 100\n",
      "489754156 0.6285140711684002 1009.9863767623901 100\n",
      "322246422 0.6631708343654288 947.3527760505676 100\n",
      "328031983 0.8412221640531027 1327.6199169158936 100\n",
      "518238899 0.0 3127.5347650051117 4\n",
      "501951290 0.0 1049.9789023399353 3\n",
      "490612150 0.0 2071.4874444007874 5\n",
      "609435731 0.0 11253.219038963318 5\n",
      "324053519 0.0 1421.8904058933258 3\n",
      "484515166 0.7410397321851105 436.2826223373413 100\n",
      "486176465 0.0 2495.628928422928 3\n",
      "566466395 0.6412384286515123 688.7072315216064 100\n",
      "487158599 0.7808425945784433 1145.182258605957 100\n",
      "561519381 0.8148302028812615 472.13165760040283 100\n",
      "521938313 0.6231298899455561 412.6457929611206 100\n",
      "369697038 0.0 1085.0165195465088 3\n",
      "609713212 0.9192540395826708 423.92228412628174 100\n",
      "476457450 0.0 907.3365807533264 100\n",
      "580007431 0.0 1137.7397050857544 3\n",
      "523748610 0.7307202700447358 994.0792999267578 100\n",
      "547336671 0.0 805.5977773666382 6\n",
      "476269122 0.42269029981386463 812.8786664009094 100\n",
      "322723785 0.7169762930189796 533.6947870254517 100\n",
      "480351780 0.6118373214219096 804.2124719619751 100\n",
      "628700262 0.5832471546155468 751.7521228790283 100\n",
      "578485753 0.0 1338.9013166427612 5\n",
      "482690728 0.9259460311507821 1304.2219820022583 100\n",
      "488698341 0.0 3241.9892888069153 3\n",
      "579414994 0.9359245017676251 457.6088972091675 100\n",
      "468120757 0.0 1267.6193346977234 3\n",
      "582778095 0.0 1765.825855255127 5\n",
      "515949222 0.7183837807699559 595.9270963668823 100\n",
      "480777144 0.6192383682330429 2873.5839133262634 100\n",
      "524689239 0.6787443350614024 267.6178798675537 100\n",
      "488688374 0.0 1434.675998210907 3\n",
      "485184849 0.9785303776610689 527.5028610229492 100\n",
      "513879001 0.0 1538.0706295967102 3\n",
      "527579814 0.6866111121859595 1348.121395111084 100\n",
      "324065524 0.7304746998887617 1151.1081676483154 100\n",
      "471819401 0.0 4742.945177555084 4\n",
      "556524816 0.6020583466903183 211.9216833114624 100\n",
      "464198958 0.6415584206245172 279.7683572769165 100\n",
      "478793814 0.954436842009539 590.9540061950684 100\n",
      "486196663 0.0 1118.2668108940125 3\n",
      "566719275 0.0 7346.015379905701 7\n",
      "323777372 0.6470512508537819 372.6639795303345 100\n",
      "396939115 0.3300415952834667 134.92883014678955 100\n",
      "596213704 0.6468144080683211 587.8006658554077 100\n",
      "482435718 0.5983878477578197 262.43588733673096 100\n",
      "490558274 0.6265145826510025 806.8542919158936 100\n",
      "521399472 0.0 1296.2999048233032 3\n",
      "501023852 0.0 880.2149157524109 3\n",
      "591627904 0.8799365114946526 334.3802089691162 100\n",
      "565407476 0.5050135144734137 219.13429164886475 100\n",
      "556369531 0.38323044032114867 332.04926586151123 100\n",
      "488681087 0.7683685408169967 725.0161519050598 100\n",
      "480169202 0.0 2013.7425990104675 3\n",
      "593579697 0.8635859967763991 460.0462017059326 100\n",
      "320455763 0.9427557429469448 1830.4281921386719 100\n",
      "476129135 0.0 701.8745365142822 3\n",
      "593646579 0.522242166394039 220.22269439697266 100\n",
      "569270348 0.9157694483350488 462.499888420105 100\n",
      "575774870 0.0 1821.9100275039673 10\n",
      "500964382 0.0 996.1419501304626 3\n",
      "561329890 0.7339321002768432 234.99509716033936 100\n",
      "522408506 0.5546819237922372 382.43261981010437 100\n",
      "589427435 0.0 634.128576040268 3\n",
      "565723357 0.7448998354762603 370.9872169494629 100\n",
      "513593674 0.0 4645.100880622864 4\n",
      "502245101 0.552595676985972 916.0136160850525 100\n",
      "482654108 0.7147161938680046 1176.1485605239868 100\n",
      "490149337 0.0 3524.288812637329 7\n",
      "473011949 0.01958181233763507 3345.015522956848 17\n",
      "501736631 0.0 2610.550938606262 5\n",
      "575637715 0.7350595974703781 417.38021183013916 100\n",
      "464079491 0.0 1740.0242111682892 3\n",
      "515305346 0.9563520733806056 1455.111071586609 100\n",
      "579627022 0.0 1450.7102756500244 5\n",
      "568767467 0.6415352744446371 523.4863834381104 100\n",
      "490259892 0.8251017958680135 309.6937503814697 100\n",
      "573410831 0.0 636.7777442932129 3\n",
      "322761772 0.0 1119.169148683548 3\n",
      "522152249 0.0 5498.665587425232 4\n",
      "572609025 0.0 1049.9789066314697 5\n",
      "476093220 0.0 1689.9568424224854 6\n",
      "504647603 0.0 1105.0017471313477 3\n",
      "479722622 0.5433782150161356 1157.727382183075 100\n",
      "487358945 0.0 1071.2552647590637 3\n",
      "586566174 0.0 1156.0781240463257 3\n",
      "599434799 0.0 4816.787108421326 7\n",
      "464188580 0.0 4767.731156349182 3\n",
      "321923492 0.0 2177.7406215667725 4\n",
      "487445455 0.0 4363.496163845062 4\n",
      "507918877 0.5796806525589501 195.50594329833984 100\n",
      "490263211 0.0 511.3510732650757 6\n",
      "594047832 0.6854344173662441 234.94205284118652 100\n",
      "476099282 0.6357452481358296 289.3098726272583 100\n",
      "555697303 0.6196648211808472 206.2822937965393 100\n",
      "585753841 0.0 10420.706312179565 4\n",
      "579662784 0.5826079594237288 1550.6634435653687 100\n",
      "481093525 0.9370483993674288 894.8587799072266 100\n",
      "563535101 0.5810444771695402 230.3392095565796 100\n",
      "527869035 0.7459231256685788 1274.1841096878052 100\n",
      "556687527 0.679788466613357 427.34648990631104 100\n",
      "566724483 0.0 2540.8461894989014 3\n",
      "490718897 0.5478636099548432 1286.3065857887268 100\n",
      "504635521 0.623002006804709 232.15072965621948 100\n",
      "596619013 0.6350844418584999 1026.237027168274 100\n",
      "476615310 0.0 2048.773591041565 4\n",
      "488697163 0.0 2235.8599433898926 3\n",
      "477127614 0.31583365248532425 545.3234167098999 100\n",
      "558583839 0.30254730303583444 681.0649070739746 100\n",
      "586074009 0.0 3926.672125339508 3\n",
      "575919223 0.6389116120673148 227.66128158569336 100\n",
      "484742372 0.9404928497667456 1246.493468284607 100\n",
      "565871856 0.0 1878.9567260742188 3\n",
      "555345752 0.8640252506091969 446.1198077201843 100\n",
      "554443833 0.7361476809087514 259.1765432357788 100\n",
      "566648315 0.5216775907265563 334.611102104187 100\n",
      "325480372 0.0 936.8050212860107 3\n",
      "488689403 0.7660660306660692 1395.43958568573 100\n",
      "609183903 0.9625645183658789 353.5140700340271 100\n",
      "479179020 0.0 2893.5803241729736 5\n",
      "513510227 0.0 1747.156705379486 3\n",
      "561552455 0.7032205713804618 191.879230260849 100\n",
      "508566646 0.0 550.7001357078552 3\n",
      "603502705 0.5706456172669772 327.02120304107666 100\n",
      "573404307 0.946587405420955 454.3995223045349 100\n",
      "501940485 0.5421665240416221 736.7290177345276 100\n",
      "524876305 0.5723011529826746 944.1622982025146 100\n",
      "515264431 0.20124898694616974 139.2114601135254 100\n",
      "514824979 0.6796088987907651 380.66618824005127 100\n",
      "479492633 0.0 3444.8042278289795 4\n",
      "504615116 0.6913153387958411 625.754744052887 100\n",
      "526951157 0.825109244300519 292.0962972640991 100\n",
      "589128508 0.6233609581983941 332.0052423477173 100\n",
      "486893033 0.0 2984.65047955513 3\n",
      "469864405 0.6575191516267389 1074.943232536316 100\n",
      "582917630 0.7694376331195323 202.82723331451416 100\n",
      "487668030 0.5087743221891018 3501.3967995643616 100\n",
      "501014504 0.7441665380657518 252.5343656539917 100\n",
      "586072783 0.6188493289389567 322.5937795639038 100\n",
      "397353539 0.4054403006256478 616.1994061470032 100\n",
      "562385794 0.2708792549756859 459.3571844100952 100\n",
      "503517607 0.6929998946145361 212.84263134002686 100\n",
      "422055317 0.0 1541.9349656105042 3\n",
      "478958894 0.9626201193543854 692.1401085853577 100\n",
      "478947222 0.0 7956.280902862549 6\n",
      "313861828 0.6255443298569848 387.6292486190796 100\n",
      "485061364 0.9073828269836324 616.1363534927368 100\n",
      "567266985 0.559671313300311 300.12905502319336 100\n",
      "475894121 0.0 18036.147248268127 4\n",
      "580895033 0.9398980628633568 459.5746774673462 100\n",
      "478412623 0.5410820395154456 711.2645196914673 100\n",
      "508980706 0.0 1890.0747599601746 5\n",
      "564438523 0.0 2037.9409818649292 6\n",
      "573105010 0.3760180895808833 120.59346944093704 100\n",
      "583804033 0.7581426888419623 247.34850311279297 100\n",
      "501282204 0.5492926387480317 1502.9176902770996 100\n",
      "524090036 0.0 1606.6553688049316 5\n",
      "328535908 0.5877791439984741 412.5727610588074 100\n",
      "571396942 0.9608221805600407 1570.2225790023804 100\n",
      "560968319 0.0 482.0543885231018 3\n",
      "327648537 0.0 8770.918066978455 3\n",
      "527089085 0.8770662305726704 363.95270442962646 100\n",
      "585080288 0.7495411375824781 512.954044342041 100\n",
      "547262585 0.6318360767237794 272.22468423843384 100\n",
      "556926517 0.5312602861719953 193.96085691452026 100\n",
      "490733962 0.8396547539423976 305.74110078811646 100\n",
      "581058351 0.9540735645730167 1240.5204753875732 100\n",
      "569424261 0.39480276131647885 280.3081603050232 100\n",
      "526939383 0.8223238718922921 417.1574296951294 100\n",
      "481093098 0.0 1718.1657090187073 3\n",
      "565870964 0.4943483018802899 489.9420280456543 100\n",
      "569715141 0.5260304116895623 291.1442699432373 100\n",
      "518271679 0.0 2852.317038536072 3\n",
      "507770911 0.0 1161.4425225257874 3\n",
      "322762730 0.0 5037.923691749573 3\n",
      "565888394 0.7009893037826097 1322.5708808898926 100\n",
      "571295641 0.6660028325155627 263.25690746307373 100\n",
      "526801742 0.7576567551063244 386.98167657852173 100\n",
      "515249852 0.0 1524.9570984840393 5\n",
      "559221786 0.7283852144811115 1306.3695268630981 100\n",
      "477880128 0.36960221716277664 271.47740173339844 100\n",
      "514544971 0.0 799.6110763549805 5\n",
      "573086094 0.6512722248322502 386.0187826156616 100\n",
      "585951863 0.8996012313877156 389.867130279541 100\n",
      "578898150 0.7620461443795683 724.5357837677002 100\n",
      "560814288 0.7429327873287868 224.4103889465332 100\n",
      "323452245 0.0 934.7781720161438 5\n",
      "486235288 0.0 709.6176629066467 5\n",
      "585018101 0.0 309.3797540664673 5\n",
      "569653118 0.46960758078890813 592.0611248016357 100\n",
      "490916919 0.6351058385839011 950.8051958084106 100\n",
      "490205998 0.0 2606.8322134017944 7\n",
      "515199779 0.6139952044960831 228.83254623413086 100\n",
      "487176969 0.0 13708.887466430664 4\n",
      "578774163 0.0 1325.3436613082886 13\n",
      "560748672 0.5267184796212988 335.78769540786743 100\n",
      "502267531 0.5595602491472004 1177.4992246627808 100\n",
      "487400838 0.9042234591035061 479.5093240737915 100\n",
      "501895840 0.0 2434.495867729187 3\n",
      "483020137 0.577183540966689 869.5499200820923 100\n",
      "489888898 0.0 3569.4035291671753 3\n",
      "478447600 0.0 2315.9745502471924 5\n",
      "484659182 0.7082561269125515 255.02404880523682 100\n",
      "592816620 0.5769271688822277 166.43917417526245 100\n",
      "476054829 0.0 899.1855120658875 3\n",
      "486198953 0.0 3704.6499919891357 4\n",
      "524693113 0.6702088585715653 721.1095399856567 100\n",
      "564349611 0.7599143787952829 338.4133720397949 100\n",
      "318808427 0.6165582045267738 347.21503496170044 100\n",
      "555060623 0.0 573.420524597168 8\n",
      "503286448 0.7929464592694331 1096.7849407196045 100\n",
      "324466858 0.46235637390169393 1294.3454904556274 100\n",
      "322781822 0.0 1267.967866897583 5\n",
      "590558808 0.936651229827635 404.1820020675659 100\n",
      "502193385 0.0 2747.7457752227783 4\n",
      "591396115 0.0 1861.8808102607727 4\n",
      "486262299 0.0 1741.252421617508 3\n",
      "482649712 0.8427674824962712 354.45264053344727 100\n",
      "569477234 0.0 3062.4103174209595 3\n",
      "488501071 0.9550905712166265 2149.236657142639 100\n",
      "484738748 0.0 1093.3032989501953 3\n",
      "567901050 0.0 18870.603985786438 5\n",
      "470098860 0.0 1593.0232503414154 100\n",
      "561520050 0.7430351140447986 216.84346675872803 100\n",
      "480087928 0.0 1001.4019966125488 4\n",
      "572410577 0.49537834673839937 201.9232931137085 100\n",
      "563220277 0.6700796277766914 433.59901428222656 100\n",
      "488679042 0.0 6031.3855719566345 3\n",
      "579652000 0.48935924550777116 470.7573666572571 100\n",
      "476056333 0.5578559632681497 313.942280292511 100\n",
      "604134393 0.0 1118.617371559143 3\n",
      "517977609 0.0 1451.9437646865845 3\n",
      "469614747 0.8692596511520856 618.0625200271606 100\n",
      "481003643 0.7640922138254003 886.6859498023987 100\n",
      "476178907 0.4896704900280952 585.3956298828125 100\n",
      "516916566 0.39293850944767966 472.0744218826294 100\n",
      "572416871 0.5040356119792124 172.9965958595276 100\n",
      "569997187 0.9508259645455109 405.5776391029358 100\n",
      "502665074 0.7366690464686371 214.01688861846924 100\n",
      "473909767 0.0 1353.1543445587158 11\n",
      "566671538 0.7466916948184377 903.9086322784424 100\n",
      "586073850 0.9462063975775699 381.4931387901306 100\n",
      "502887600 0.0 965.1042461395264 4\n",
      "328015342 0.7100825905649576 1117.8899457454681 100\n",
      "559387643 0.0 735.4238228797913 5\n",
      "476452460 0.5028258833657386 333.9752140045166 100\n",
      "480778441 0.0 1699.7736954689026 3\n",
      "329241587 0.0 2903.019585609436 4\n",
      "583817628 0.7710692195743023 469.67065715789795 100\n",
      "558476932 0.0 807.8784670829773 3\n",
      "491029832 0.806110400829951 302.99840259552 100\n",
      "520347870 0.5063310804149823 288.9912223815918 100\n",
      "509003464 0.0 6214.563681602478 4\n",
      "422738880 0.0 1225.118984222412 4\n",
      "503254105 0.6521291027388277 2085.239736557007 100\n",
      "586072464 0.6012774423941105 443.41495513916016 100\n",
      "547344442 0.4332348524701362 334.3891305923462 100\n",
      "329557305 0.0 1513.6021265983582 3\n",
      "554454165 0.7889712202746083 409.64171981811523 100\n",
      "480952106 0.0 13746.632551193237 5\n",
      "469753383 0.0 5177.163282394409 3\n",
      "464191630 0.6990184497189504 136.37936305999756 100\n",
      "589452470 0.0 5924.3796401023865 3\n",
      "581020172 0.7918078781099341 3912.6078662872314 100\n",
      "561325425 0.9207631621177461 269.498779296875 100\n",
      "591265629 0.41380406441123996 223.90648806095123 100\n",
      "476686112 0.6774881557858294 816.932731628418 100\n",
      "482516631 0.0 31399.901273727417 4\n",
      "522257166 0.6049369491147762 311.73078536987305 100\n",
      "485287282 0.4518208306285831 613.5987100601196 100\n",
      "584671501 0.0 1776.2458057403564 4\n",
      "577218818 0.0 1883.677412033081 6\n",
      "553219924 0.7108604488243122 348.15442276000977 100\n",
      "584271064 0.7035261335005732 1074.2749557495117 100\n",
      "515202564 0.0 1119.5823545455933 3\n",
      "599170940 0.0 990.3131108283997 3\n",
      "475895240 0.94661884006462 1139.675850868225 100\n",
      "467357834 0.0 1562.0091128349304 3\n",
      "530204927 0.0 577.565167427063 3\n",
      "485934207 0.0 1144.4539370536804 3\n",
      "573976402 0.21044648233391428 586.2695751190186 100\n",
      "485889190 0.0 1927.044183731079 4\n",
      "583836069 0.0 327.57183933258057 5\n",
      "485245025 0.8571868386072996 2199.974429130554 100\n",
      "482773968 0.0 5051.077028274536 3\n",
      "484744672 0.5085633522095196 5221.206112861633 100\n",
      "596789749 0.0 423.5222010612488 3\n",
      "562965437 0.005612918072912683 1417.580906867981 27\n",
      "475585413 0.726710520944087 1022.0776281356812 100\n",
      "596282602 0.0 1215.6999497413635 3\n",
      "341016267 0.9574286286316572 487.85002756118774 100\n",
      "466664172 0.5463052413911771 582.2492551803589 100\n",
      "478396248 0.6952180609039803 352.5865201950073 100\n",
      "526785742 0.6728373297059749 1331.0892724990845 100\n",
      "474283475 0.6842934511491292 850.8345379829407 100\n",
      "563353582 0.0 724.7515678405762 3\n",
      "325464516 0.0 1086.0103182792664 3\n",
      "585740198 0.46804491336230425 2899.6897192001343 100\n",
      "562091859 0.0 260.862247467041 100\n",
      "491026389 0.6412025030571552 1496.9815244674683 100\n",
      "485577686 0.0 1533.0467309951782 3\n",
      "490170480 0.0 941.2089624404907 4\n",
      "575200757 0.5738110295514469 218.97897100448608 100\n",
      "476053392 0.0 1263.997703075409 3\n",
      "477135941 0.4709789212994586 564.8508853912354 100\n",
      "501562903 0.0 2700.7528829574585 7\n",
      "585944237 0.612260629617552 360.147442817688 100\n",
      "397129612 0.0 1458.1457014083862 5\n",
      "502978383 0.0 1457.6015787124634 6\n",
      "586358539 0.8699313563717663 488.28415393829346 100\n",
      "500964358 0.0 678.751015663147 3\n",
      "490283519 0.0 668.2693462371826 3\n",
      "469734859 0.0 768.1424057483673 4\n",
      "486753754 0.6119772624906464 284.3812303543091 100\n",
      "479993900 0.0 3598.3890285491943 5\n",
      "591626585 0.5238787193372044 523.4813289642334 100\n",
      "314900022 0.6210806942330429 299.90893936157227 100\n",
      "563226105 0.0 1516.0854530334473 3\n",
      "480122859 0.0 649.3290777206421 3\n",
      "566761793 0.8308648833292868 1239.5464458465576 100\n",
      "527095729 0.8553687522355258 536.4841260910034 100\n",
      "483099796 0.0 532.9740109443665 5\n",
      "517345160 0.16348072573458544 462.48007678985596 100\n",
      "504567071 0.0 1059.8030860424042 3\n",
      "517647182 0.35951519066821497 405.74244117736816 100\n",
      "490263438 0.785573843501172 1427.5281620025635 100\n",
      "579981789 0.0 7036.0951290130615 4\n",
      "502366405 0.0 1433.8367376327515 3\n",
      "570924514 0.6349859757471333 549.8823890686035 100\n",
      "522418855 0.8748300481688717 426.49468755722046 100\n",
      "567399060 0.0 1871.3790864944458 3\n",
      "487405644 0.9100659175176107 430.0167474746704 100\n",
      "479298854 0.9551422901232688 1726.5635089874268 100\n",
      "501730497 0.6460987809592107 277.89013862609863 100\n",
      "485608017 0.0 3162.2285866737366 3\n",
      "502999078 0.566664018605546 337.33594608306885 100\n",
      "585948651 0.8449642592827866 483.98991107940674 100\n",
      "503814817 0.6520897746801889 1235.4532799720764 100\n",
      "323838579 0.0 3695.9534249305725 4\n",
      "569810649 0.80934718272177 996.6830711364746 100\n",
      "481127348 0.8525874392124855 1394.4156255722046 100\n",
      "593618144 0.9291881527250488 1677.5132570266724 100\n",
      "595511209 0.0 1074.5396642684937 3\n",
      "502143149 0.39554751060281973 378.6313302516937 100\n",
      "572827931 0.0 1069.9607882499695 3\n",
      "490172112 0.0 954.1978130340576 3\n",
      "524850271 0.0 466.6572937965393 4\n",
      "563350008 0.0 1479.8102493286133 3\n",
      "501570114 0.707366227979293 938.3801798820496 100\n",
      "569317896 0.0 1628.8818016052246 7\n",
      "487638658 0.0 4766.429329872131 5\n",
      "580149939 0.2820807116198208 419.0128536224365 100\n",
      "574992320 0.0 10111.174299240112 5\n",
      "591616101 0.2891478400481614 203.42510414123535 100\n",
      "478716304 0.6760719842860061 815.2297325134277 100\n",
      "563620254 0.8881065825190249 419.7694673538208 100\n",
      "579611597 0.8154556679582564 485.571120262146 100\n",
      "324025371 0.0 1036.2346291542053 4\n",
      "482910438 0.450701671866091 278.6702151298523 100\n",
      "593436526 0.7522675614527771 271.2583341598511 100\n",
      "570098593 0.5724007126500492 304.8842782974243 100\n",
      "508883033 0.0 1418.9290266036987 6\n",
      "500966656 0.7540442975742421 181.00682640075684 100\n",
      "560738452 0.9110535038205424 488.0233335494995 100\n",
      "579672464 0.6713523602374453 4416.4544506073 100\n",
      "314822529 0.6453069836768185 969.6237320899963 100\n",
      "477490421 0.9335564527786355 1187.1693181991577 100\n",
      "490376252 0.7615066226283033 1409.517734527588 100\n",
      "584561230 0.5762250069327879 312.0070638656616 100\n",
      "485610263 0.0 1023.7065320014954 3\n",
      "486146717 0.0 880.3551135063171 3\n",
      "481136214 0.7666904148581901 1652.5018787384033 100\n",
      "558076716 0.0 1193.3585243225098 3\n",
      "560690291 0.0 1994.0849657058716 8\n",
      "488501165 0.7305209239110477 741.6234664916992 100\n",
      "370351753 0.0 1252.290617465973 3\n",
      "475848827 0.560551580063793 135.1540412902832 100\n",
      "486352114 0.8514284474515635 1876.3638954162598 100\n",
      "581058864 0.7790702342463193 322.3796720504761 100\n",
      "564410881 0.858854426721641 607.6832790374756 100\n",
      "318733871 0.5946810153348666 616.6028966903687 100\n",
      "564346637 0.5502642090842953 417.04473972320557 100\n",
      "594091004 0.7374271065440522 211.4956865310669 100\n",
      "483101699 0.0 3814.932806968689 3\n",
      "485570372 0.40988091013675926 342.9492812156677 100\n",
      "475622680 0.7053017135144406 772.5933122634888 100\n",
      "482726727 0.0 1498.508990764618 5\n",
      "526946319 0.0 1746.5837717056274 3\n",
      "487446992 0.0 1873.982985496521 3\n",
      "486560376 0.0 1346.098618030548 3\n",
      "473951795 0.4864650638686461 114.99886703491211 100\n",
      "609775336 0.9509542620009921 467.417986869812 100\n",
      "500859045 0.8020882439485942 430.5120449066162 100\n",
      "559388218 0.0 768.1724338531494 7\n",
      "573680326 0.6035321677895343 500.2962808609009 100\n",
      "479728896 0.0 1984.481128692627 3\n",
      "322197295 0.5837210471694163 596.945216178894 100\n",
      "566563603 0.6261111083525682 1002.2798519134521 100\n",
      "605889373 0.0 2497.2057695388794 5\n",
      "320639930 0.5711917800332539 939.5109667778015 100\n",
      "518750800 0.815932033535234 1591.7220358848572 100\n",
      "583148615 0.0 2123.2237606048584 4\n",
      "583822407 0.6450695959044509 184.31476974487305 100\n",
      "481003593 0.7828641846661117 851.097409248352 100\n",
      "591622050 0.2730818626942168 849.7597064971924 100\n",
      "596808442 0.9354086960246748 293.78319549560547 100\n",
      "570010469 0.7110967531695735 332.737606048584 100\n",
      "566475818 0.32701967152706407 563.1295509338379 100\n",
      "504643398 0.0 1206.9146790504456 3\n",
      "596609577 0.0 10121.249623298645 5\n",
      "571292875 0.0 1401.1048550605774 4\n",
      "497611660 0.0 2088.9409070014954 3\n",
      "508887004 0.2705346028453246 1056.1548147201538 100\n",
      "585805211 0.9725232809961288 438.13412165641785 100\n",
      "490267468 0.6510664653359106 878.7266054153442 100\n",
      "490612844 0.4426082409419766 785.6246218681335 100\n",
      "531342116 0.0018751364916445355 438.89073038101196 100\n",
      "486029942 0.0 1398.4441356658936 4\n",
      "479225294 0.6558986184740127 654.1863956451416 100\n",
      "560686477 0.8423489804409835 2626.8769426345825 100\n",
      "583403073 0.0 21254.069803237915 6\n",
      "592833901 0.6114347125580882 175.556658744812 100\n",
      "328093618 0.0 467.27130794525146 5\n",
      "566991946 0.48760218086628193 184.57428455352783 100\n",
      "565858209 0.0 862.8076977729797 3\n",
      "569710450 0.0 4311.180106163025 5\n",
      "575782162 0.0 940.0685482025146 5\n",
      "466827702 0.37804570965624207 318.2645664215088 100\n",
      "566720165 0.3876455888652715 198.36706447601318 100\n",
      "585955070 0.0 2618.6037549972534 3\n",
      "501891177 0.6559978751209479 247.7679796218872 100\n",
      "486146828 0.0 897.3942604064941 3\n",
      "505808144 0.8109684718850331 655.2166528701782 100\n",
      "606517484 0.9459939173159875 317.6332597732544 100\n",
      "565213849 0.3719750595736107 152.3906364440918 100\n",
      "313861677 0.5511468408445688 509.3893299102783 100\n",
      "488674910 0.8570516912396032 319.5975151062012 100\n",
      "623379534 0.4791657018435285 142.82064151763916 100\n",
      "490982660 0.0 2424.774007797241 5\n",
      "571314481 0.8360120796895014 719.838080406189 100\n",
      "476764144 0.0 2106.9421043395996 5\n",
      "575299891 0.45573754158721563 365.8824644088745 100\n",
      "323834998 0.8265736798640737 904.3670344352722 100\n",
      "572376830 0.0 10524.244998931885 5\n",
      "487353993 0.605008401266699 359.6935224533081 100\n",
      "386970660 0.5924226756245965 185.3988537788391 100\n",
      "565871768 0.0 3924.9402360916138 5\n",
      "589760138 0.6318835766334238 493.93965244293213 100\n",
      "480090260 0.6868433545005082 827.0480532646179 100\n",
      "320207387 0.0 4441.225654602051 4\n",
      "479219923 0.6568441229616329 146.43967533111572 100\n",
      "574038330 0.0 1115.7347140312195 3\n",
      "486921382 0.6410021722693441 917.9686970710754 100\n",
      "579662957 0.944438112046612 318.26336765289307 100\n",
      "480169278 0.641301547320045 861.6383118629456 100\n",
      "590876255 0.9559970536023611 350.30124950408936 100\n",
      "330080937 0.0 8903.33966255188 5\n",
      "480735016 0.3595667942673808 1409.2153882980347 100\n",
      "575642695 0.47903973228456376 404.9401569366455 100\n",
      "485955982 0.5480506387909204 720.2000007629395 100\n",
      "490772223 0.0 2325.502848148346 4\n",
      "486132712 0.7082261167582604 1641.6740856170654 100\n",
      "566517779 0.5814882233997849 566.0991497039795 100\n",
      "367567889 0.0 836.1455183029175 5\n",
      "485574721 0.0 2361.8373444080353 3\n",
      "202 533 0.3789868667917448\n"
     ]
    }
   ],
   "source": [
    "zeros = 0\n",
    "low_evr = []\n",
    "for cell_id in params:\n",
    "    evr = params[cell_id][\"evr\"]\n",
    "    losses = params[cell_id][\"losses\"]\n",
    "    print(cell_id, evr, losses[-1], len(losses))\n",
    "    if evr == 0:\n",
    "        zeros += 1\n",
    "    if evr < 0.4 or losses[-1] > 1000:\n",
    "        low_evr.append(cell_id)\n",
    "print(zeros, len(params), zeros / len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71456845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295\n"
     ]
    }
   ],
   "source": [
    "print(len(low_evr))\n",
    "with open(\"misc/cell_ids_rerun.csv\", \"w\") as f:\n",
    "    f.write(\",\".join(map(str, low_evr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a48372dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model/max_firing_rates.pickle\", \"rb\") as f:\n",
    "    a = pickle.load(f)\n",
    "    \n",
    "with open(\"misc/cell_ids_mfr.csv\", \"w\") as f:\n",
    "    f.write(\",\".join(map(str, a.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6003c356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
