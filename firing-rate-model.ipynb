{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55504ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.utils\n",
    "\n",
    "from model import FiringRateModel, PolynomialActivation, train_model\n",
    "from data import load_data, preprocess_data, get_train_test_data\n",
    "from evaluate import explained_variance_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf70056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"mps\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59b775ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(model, Is, fs, evr=None):    \n",
    "    pred_fs = model.predict(Is)\n",
    "    ts = np.arange(len(Is)) * bin_size / 1000\n",
    "    fig, axs = plt.subplots(2)\n",
    "    \n",
    "    if evr is not None:\n",
    "        fig.suptitle(f\"cell_id={cell_id}, bin_size={bin_size}, k={k}, l={l}, evr={evr[0]:.3f}/{evr[1]:.3f}\")\n",
    "    else:\n",
    "        fig.suptitle(f\"cell_id={cell_id}, bin_size={bin_size}, k={k}, l={l}\")\n",
    "        \n",
    "    axs[0].plot(ts, fs)\n",
    "    axs[0].plot(ts, pred_fs)\n",
    "    axs[1].plot(ts, Is)\n",
    "    axs[0].set_ylabel(\"firing rate\")\n",
    "    axs[1].set_ylabel(\"current (pA)\")\n",
    "    axs[1].set_xlabel(\"time (s)\")\n",
    "    \n",
    "def train(cell_id, bin_size, k, l, loss_fn, save=True):\n",
    "    Is_tr, fs_tr, Is_te, fs_te = get_train_test_data(data, cell_id, bin_size, device=device)\n",
    "    Is_tr, fs_tr = sklearn.utils.shuffle(Is_tr, fs_tr)\n",
    "    \n",
    "    actv = PolynomialActivation()\n",
    "    actv.init_from_file(f\"model/activation/{loss_fn}/bin_size_{bin_size}/{cell_id}_1e-05.pickle\")\n",
    "\n",
    "    model = FiringRateModel(actv, k=k, l=l).to(device)\n",
    "    if loss_fn == \"poisson\":\n",
    "        criterion = torch.nn.PoissonNLLLoss(log_input=False)\n",
    "    elif loss_fn == \"huber\":\n",
    "        criterion = torch.nn.HuberLoss()\n",
    "        #criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "    \n",
    "    epochs = 1 if k == 0 and l == 0 else 50\n",
    "    print_every = 1 if k == 0 and l == 0 else 10\n",
    "    train_model(\n",
    "        model, \n",
    "        criterion, \n",
    "        optimizer,\n",
    "        Is_tr,\n",
    "        fs_tr,\n",
    "        epochs = epochs,\n",
    "        print_every = print_every,\n",
    "        loss_fn = loss_fn,\n",
    "        bin_size = bin_size,\n",
    "        up_factor = 5\n",
    "    )\n",
    "    \n",
    "    for i in range(len(Is_tr)):\n",
    "        if not torch.all(fs_tr[i] <= 0.01):\n",
    "            plot_predictions(model, Is_tr[i], fs_tr[i], evr=None)\n",
    "            if save:\n",
    "                plt.savefig(f\"figures/model/bin_size_{bin_size}/{cell_id}_{k}_{l}_{i}.png\")\n",
    "                plt.close()\n",
    "    \n",
    "    r = explained_variance_ratio(model, Is_te, fs_te, bin_size)\n",
    "    rq = explained_variance_ratio(model, Is_te, fs_te, bin_size, quantize=True)\n",
    "    plot_predictions(model, Is_te[0], fs_te[0], evr=(r, rq))\n",
    "    if save:\n",
    "        plt.savefig(f\"figures/model/bin_size_{bin_size}/{cell_id}_{k}_{l}_noise2.png\")\n",
    "        plt.close()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9ec2655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([583836069, 565871768, 605889373])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data(with_zero=True)\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51bdf93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_id=583836069, bin_size=20, k=0, l=0\n",
      "Epoch 1 / Loss: 11918.103953152895\n",
      "[] []\n",
      "cell_id=583836069, bin_size=20, k=0, l=1\n",
      "Epoch 10 / Loss: 11866.666827082634\n",
      "Epoch 20 / Loss: 11813.96374103427\n",
      "Epoch 30 / Loss: 11762.358575612307\n",
      "Epoch 40 / Loss: 11711.832786798477\n",
      "Epoch 50 / Loss: 11662.294202625751\n",
      "[] [82.23571014404297]\n",
      "cell_id=583836069, bin_size=20, k=1, l=0\n",
      "Epoch 10 / Loss: 2739.8150255978107\n",
      "Epoch 20 / Loss: 2739.7977062165737\n",
      "Epoch 30 / Loss: 2739.7719454169273\n",
      "Epoch 40 / Loss: 2739.736669033766\n",
      "Epoch 50 / Loss: 2739.690047621727\n",
      "[-1.444038987159729] []\n",
      "cell_id=583836069, bin_size=20, k=1, l=1\n",
      "Epoch 10 / Loss: 2741.338117226027\n",
      "Epoch 20 / Loss: 2741.219035744667\n",
      "Epoch 30 / Loss: 2741.074725329876\n",
      "Epoch 40 / Loss: 2740.8755066394806\n",
      "Epoch 50 / Loss: 2740.6097138524055\n",
      "[-1.6595782041549683] [0.9941470623016357]\n",
      "cell_id=583836069, bin_size=20, k=2, l=0\n",
      "Epoch 10 / Loss: 1998.8511716127396\n",
      "Epoch 20 / Loss: 1604.054558366537\n",
      "Epoch 30 / Loss: 2469.0817211270332\n",
      "Epoch 40 / Loss: 1857.8054823800921\n",
      "Epoch 50 / Loss: 1572.013396114111\n",
      "[-2.574521780014038, 1.2948023080825806] []\n",
      "cell_id=583836069, bin_size=20, k=2, l=1\n",
      "Epoch 10 / Loss: 2180.7887476682663\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_id=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcell_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, bin_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbin_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, k=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, l=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ml\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbin_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpoisson\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     params[(cell_id, bin_size, k, l)] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m: model\u001b[38;5;241m.\u001b[39ma\u001b[38;5;241m.\u001b[39mtolist(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m: model\u001b[38;5;241m.\u001b[39mb\u001b[38;5;241m.\u001b[39mtolist()}\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39ma\u001b[38;5;241m.\u001b[39mtolist(), model\u001b[38;5;241m.\u001b[39mb\u001b[38;5;241m.\u001b[39mtolist())\n",
      "Cell \u001b[0;32mIn[3], line 35\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(cell_id, bin_size, k, l, loss_fn, save)\u001b[0m\n\u001b[1;32m     33\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m l \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m50\u001b[39m\n\u001b[1;32m     34\u001b[0m print_every \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m l \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m---> 35\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mIs_tr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfs_tr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbin_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbin_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mup_factor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m     46\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(Is_tr)):\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(fs_tr[i] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/GitHub/GRNN/model.py:137\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, Is_tr, fs_tr, epochs, print_every, loss_fn, bin_size, up_factor)\u001b[0m\n\u001b[1;32m    135\u001b[0m fs \u001b[38;5;241m=\u001b[39m pred_fs[i\u001b[38;5;241m-\u001b[39ml:i]\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m#print(pred_fs, fs, model.b)\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m pred_fs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((pred_fs, f\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss_fn \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoisson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GitHub/GRNN/model.py:32\u001b[0m, in \u001b[0;36mFiringRateModel.forward\u001b[0;34m(self, currents, fs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     28\u001b[0m     currents, \u001b[38;5;66;03m# currents tensor, size k+1 (t-k,...,t)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     fs \u001b[38;5;66;03m# firing rates, size l (t-l,...,t-1)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m ):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 32\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrents\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcurrents\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg(currents[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb \u001b[38;5;241m@\u001b[39m fs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GitHub/GRNN/model.py:57\u001b[0m, in \u001b[0;36mPolynomialActivation.forward\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m     55\u001b[0m x \u001b[38;5;241m=\u001b[39m (z \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_current\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m#poly = F.relu(self.poly_coeff) @ x.pow(self.p) # relu to ensure monotonicity\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m poly \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoly_coeff\u001b[49m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m@\u001b[39m x\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp)\n\u001b[1;32m     58\u001b[0m tan \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_firing_rate \u001b[38;5;241m*\u001b[39m F\u001b[38;5;241m.\u001b[39mtanh(poly) \u001b[38;5;66;03m# ceil is the max firing rate\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mrelu(tan)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1601\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_backward_pre_hooks\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1599\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[0;32m-> 1601\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModule\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m   1602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1603\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "for cell_id in [583836069, 565871768, 605889373]:\n",
    "    for bin_size in [20, 50, 100]:\n",
    "        for k in [0, 1, 2]:\n",
    "            for l in [0, 1]:\n",
    "                print(f\"cell_id={cell_id}, bin_size={bin_size}, k={k}, l={l}\")\n",
    "                model = train(cell_id, bin_size, k, l, \"poisson\", save=True)\n",
    "                params[(cell_id, bin_size, k, l)] = {\"a\": model.a.tolist(), \"b\": model.b.tolist()}\n",
    "                print(model.a.tolist(), model.b.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8490949",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
