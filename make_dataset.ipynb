{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c388ba-3100-43e6-b25d-9d8997d7197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from model import GFR\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.options.display.float_format = '{:,.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bd7b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(params, threshold=0.6):\n",
    "    with open(\"model/labels.pickle\", \"rb\") as f:\n",
    "        labels = pickle.load(f)\n",
    "    \n",
    "    chosen_ids = filter(lambda x: params[x][\"evr2\"] >= threshold, params.keys())\n",
    "    \n",
    "    dataset = {}\n",
    "    for cell_id in chosen_ids:\n",
    "        y = labels[cell_id]\n",
    "        p = params[cell_id][\"params\"]\n",
    "        model = GFR.from_params(p)\n",
    "        \n",
    "        a = p[\"a\"].reshape(-1)\n",
    "        b = p[\"b\"].reshape(-1)\n",
    "        pc = p[\"g\"][\"poly_coeff\"].reshape(-1)\n",
    "        gb = p[\"g\"][\"b\"].reshape(-1)\n",
    "        mc = p[\"g\"][\"max_current\"].reshape(-1)\n",
    "        mfr = p[\"g\"][\"max_firing_rate\"].reshape(-1)\n",
    "        x = torch.cat([a, b, pc, gb, mc, mfr])\n",
    "        \n",
    "        dataset[cell_id] = (x, y, params[cell_id][\"evr2\"])\n",
    "        \n",
    "    return dataset\n",
    "    \n",
    "def get_params(bin_size, activation_bin_size, C, patch_seq=False):\n",
    "    params = {}\n",
    "    save_path = f\"model/params/{bin_size}_{activation_bin_size}_{C}/\"\n",
    "    if patch_seq:\n",
    "        save_path = f\"model/params/patch_seq_{bin_size}_{activation_bin_size}_{C}/\"\n",
    "    for fname in os.listdir(save_path):\n",
    "        if fname.endswith(\".pickle\"):\n",
    "            cell_id = int(fname.split(\".\")[0])\n",
    "            with open(f\"{save_path}{fname}\", \"rb\") as f:\n",
    "                params[cell_id] = pickle.load(f)\n",
    "    return params\n",
    "\n",
    "def get_all_params(patch_seq=False):\n",
    "    bin_sizes = [10, 20, 50, 100]\n",
    "    activation_bin_sizes = [20, 100]\n",
    "    C = [1, 0.5, 0.1, 0.05, 0.01, 0.005, 0.001, 0]\n",
    "    \n",
    "    params = {}\n",
    "    \n",
    "    for bin_size in bin_sizes:\n",
    "        for activation_bin_size in activation_bin_sizes:\n",
    "            if activation_bin_size >= bin_size:\n",
    "                for c in C:\n",
    "                    params[(bin_size, activation_bin_size, c)] = get_params(bin_size, activation_bin_size, c, patch_seq=patch_seq)\n",
    "                                \n",
    "    return params\n",
    "\n",
    "# summarize params of one configuration\n",
    "def summarize(params):\n",
    "    data = {\"cell_id\": [], \"evr1\": [], \"evr2\": [], \"loss\": [], \"epochs\": []}\n",
    "\n",
    "    for cell_id in params:\n",
    "        data[\"cell_id\"].append(cell_id)\n",
    "        data[\"evr1\"].append(params[cell_id][\"evr1\"])\n",
    "        data[\"evr2\"].append(params[cell_id][\"evr2\"])\n",
    "        data[\"loss\"].append(params[cell_id][\"train_losses\"][-1])\n",
    "        data[\"epochs\"].append(len(params[cell_id][\"train_losses\"]))\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.set_index(\"cell_id\")\n",
    "    df = df.sort_values(\"evr2\")\n",
    "    df_corrected = df[df[\"evr1\"] > 0.01].dropna()\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        return {}\n",
    "    \n",
    "    return {\n",
    "        \"n_cells\": len(df),\n",
    "        \"p_zero_evr\": len(df[df['evr2'] < 0.01]) / len(df),\n",
    "        \"p_early_stop\": len(df[df['epochs'] < 50]) / len(df),\n",
    "        \"median_evr\": np.median(df_corrected['evr2'].values)\n",
    "    }\n",
    "\n",
    "def get_best_params_for_actv_bin_size(params, bin_size, actv_bin_size):\n",
    "    best_params = {}\n",
    "    \n",
    "    cell_ids = set()\n",
    "    for config in params:\n",
    "        cell_ids = cell_ids.union(set(params[config].keys()))\n",
    "    \n",
    "    for cell_id in cell_ids:\n",
    "        best_config = None\n",
    "        best_evr = -1e10\n",
    "        \n",
    "        for config in params:\n",
    "            if config[0] == bin_size and config[1] == actv_bin_size and cell_id in params[config] and params[config][cell_id][\"evr1\"] > best_evr:\n",
    "                best_evr = params[config][cell_id][\"evr1\"]\n",
    "                best_config = config\n",
    "        \n",
    "        # deals with NaN values\n",
    "        if best_config is not None:\n",
    "            best_params[cell_id] = params[best_config][cell_id]\n",
    "        \n",
    "    return best_params\n",
    "    \n",
    "def get_best_params(params, bin_size):\n",
    "    best_params = {}\n",
    "    \n",
    "    cell_ids = set()\n",
    "    for config in params:\n",
    "        cell_ids = cell_ids.union(set(params[config].keys()))\n",
    "    \n",
    "    for cell_id in cell_ids:\n",
    "        best_config = None\n",
    "        best_evr = -1e10\n",
    "        \n",
    "        for config in params:\n",
    "            if config[0] == bin_size and cell_id in params[config] and params[config][cell_id][\"evr1\"] > best_evr:\n",
    "                best_evr = params[config][cell_id][\"evr1\"]\n",
    "                best_config = config\n",
    "        \n",
    "        # doesn't make sense\n",
    "        if best_config is not None:\n",
    "            best_params[cell_id] = params[best_config][cell_id]\n",
    "        \n",
    "    return best_params\n",
    "\n",
    "def visualize_data(params):\n",
    "    data = {\"cell_id\": [], \"evr1\": [], \"evr2\": [], \"loss\": [], \"epochs\": []}\n",
    "\n",
    "    for cell_id in params:\n",
    "        data[\"cell_id\"].append(cell_id)\n",
    "        data[\"evr1\"].append(params[cell_id][\"evr1\"])\n",
    "        data[\"evr2\"].append(params[cell_id][\"evr2\"])\n",
    "        data[\"loss\"].append(params[cell_id][\"train_losses\"][-1])\n",
    "        data[\"epochs\"].append(len(params[cell_id][\"train_losses\"]))\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.set_index(\"cell_id\")\n",
    "    df = df.sort_values(\"evr2\")\n",
    "\n",
    "    print(f\"Total number of cells: {len(df)}\")\n",
    "    print(f\"Number/proportion of cells with evr<=0: {len(df[df['evr2'] <= 0])}/{len(df[df['evr2'] <= 0]) / len(df)}\")\n",
    "    print(f\"Number/proportion of cells with epochs<50: {len(df[df['epochs'] < 50])}/{len(df[df['epochs'] < 50]) / len(df)}\")\n",
    "\n",
    "    df_corrected = df[df[\"evr2\"].notna()]\n",
    "    print(f\"Median evr: {np.median(df_corrected.dropna()['evr2'].values)}\")\n",
    "\n",
    "    evrs1 = df_corrected.iloc[:, 0]\n",
    "    evrs2 = df_corrected.iloc[:, 1]\n",
    "    losses = df_corrected.iloc[:, 2]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(evrs2, bins=\"auto\")\n",
    "    plt.xlabel(\"evr2\")\n",
    "    plt.ylabel(\"counts\")\n",
    "    plt.title(\"evr2 histogram (failed optimizations removed)\")\n",
    "\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.hist(losses, bins=\"auto\")\n",
    "    plt.xlabel(\"loss\")\n",
    "    plt.ylabel(\"counts\")\n",
    "    plt.title(\"loss histogram (failed optimizations removed)\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(evrs2, losses, alpha=0.5)\n",
    "    plt.xlabel(\"evr2\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.title(\"evr2 vs loss scatter plot (failed optimizations removed)\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(evrs1, evrs2, alpha=0.5)\n",
    "    plt.xlabel(\"evr1\")\n",
    "    plt.ylabel(\"evr2\")\n",
    "    plt.title(\"evr1 vs evr2 scatter plot (failed optimizations removed)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def summarize_all_models(all_params):\n",
    "    summ = {}\n",
    "    for config in all_params:\n",
    "        summ[f\"bin_size={config[0]}, activation_bin_size={config[1]}, C={config[2]}\"] = summarize(all_params[config])\n",
    "    for bin_size in [10, 20, 50, 100]:\n",
    "        for actv_bin_size in [20, 100]:\n",
    "            if bin_size <= actv_bin_size:\n",
    "                best_params = get_best_params_for_actv_bin_size(all_params, bin_size, actv_bin_size)\n",
    "                summ[f\"Best for {bin_size=}, {actv_bin_size=}:\"] = summarize(best_params)\n",
    "    for bin_size in [10, 20, 50, 100]:\n",
    "        best_params = get_best_params(all_params, bin_size)\n",
    "        summ[f\"Best for {bin_size=}:\"] = summarize(best_params)\n",
    "    print(nice_dict(summ))\n",
    "    \n",
    "def nice_dict(d, indent=0):\n",
    "    s = []\n",
    "    for i in d:\n",
    "        if type(d[i]) == dict:\n",
    "            s.append(f\"{i}\\n{nice_dict(d[i], indent=indent+1)}\")\n",
    "        elif type(d[i]) == float:\n",
    "            s.append(f\"{i}: {d[i]:.4f}\")\n",
    "        else:\n",
    "            s.append(f\"{i}: {d[i]}\")\n",
    "    return \"\\n\".join([\"| \"*indent + x for x in s])\n",
    "\n",
    "def save_best_params(all_params):\n",
    "    best_params = {}\n",
    "    for bin_size in [10, 20, 50, 100]:\n",
    "        for actv_bin_size in [20, 100]:\n",
    "            if bin_size <= actv_bin_size:\n",
    "                best_params[(bin_size, actv_bin_size)] = get_best_params_for_actv_bin_size(all_params, bin_size, actv_bin_size)\n",
    "    with open(\"model/best_params.pickle\", \"wb\") as f:\n",
    "        pickle.dump(best_params, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def get_line_name(df, cell_id):\n",
    "    return df[df[\"specimen__id\"] == cell_id][\"line_name\"].to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee80c404",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model/best_params_99_full.pickle\", \"rb\") as f:\n",
    "    all_params = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67698abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"data/metadata.csv\")\n",
    "\n",
    "d = {\n",
    "    \"cell_id\": [], \n",
    "    \"cell_type\": [], \n",
    "    \"bin_size\": [], \n",
    "    \"actv_bin_size\": [], \n",
    "    \"val_evr\": [], \n",
    "    \"test_evr\": [],\n",
    "    \"train_mse\": [],\n",
    "    \"test_mse\": [],\n",
    "    \"params\": []\n",
    "}\n",
    "\n",
    "for bin_size, actv_bin_size in all_params:\n",
    "    params = all_params[(bin_size, actv_bin_size)]\n",
    "    for cell_id in params:\n",
    "        p = params[cell_id][\"params\"]\n",
    "        cell_type = get_line_name(df2, cell_id)\n",
    "        val_evr = params[cell_id][\"evr1\"]\n",
    "        test_evr = params[cell_id][\"evr2\"]\n",
    "        train_mse = params[cell_id][\"train_losses\"][-1]\n",
    "        test_mse = params[cell_id][\"test_losses\"][-1]\n",
    "\n",
    "        d[\"cell_id\"].append(cell_id)\n",
    "        d[\"cell_type\"].append(cell_type)\n",
    "        d[\"bin_size\"].append(bin_size)\n",
    "        d[\"actv_bin_size\"].append(actv_bin_size)\n",
    "        d[\"val_evr\"].append(val_evr)\n",
    "        d[\"test_evr\"].append(test_evr)\n",
    "        d[\"train_mse\"].append(train_mse)\n",
    "        d[\"test_mse\"].append(test_mse)\n",
    "        d[\"params\"].append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1ee7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12e6a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[\"cell_id\"] == 480116737) & (df[\"bin_size\"] == 10) & (df[\"actv_bin_size\"] == 20)][\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d562c44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GFR.from_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080579da",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = params[cell_id][\"params\"]\n",
    "model = GFR.from_params(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1974df4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params[cell_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff46ad10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
