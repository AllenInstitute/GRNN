{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be2019eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model import BatchEKFR, BatchPolynomialActivation, PolynomialActivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "184517f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneralizedFiringRateModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        g, # activation function\n",
    "        k: int, # number of previous timesteps for current I\n",
    "        l: int, # number of timesteps for firing rate\n",
    "        bin_size = 0,\n",
    "        freeze_g: bool = True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.g = g\n",
    "        self.k = k\n",
    "        self.l = l\n",
    "        self.a = torch.nn.Parameter(torch.zeros(k))\n",
    "        self.b = torch.nn.Parameter(torch.zeros(l))\n",
    "        self.bin_size = bin_size\n",
    "        \n",
    "        # freeze activation parameters\n",
    "        if freeze_g: g.freeze_parameters()\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        currents, # currents tensor, up to time t\n",
    "        fs # firing rates, up to time t-1\n",
    "    ):\n",
    "        x = self.a @ currents[-self.k:]\n",
    "        y = 1000 * self.b @ fs[-self.l:]\n",
    "        return self.g(x + y)\n",
    "    \n",
    "    def smoothness_reg(self):\n",
    "        a = torch.cat([torch.tensor([0.0]), self.a])\n",
    "        b = torch.cat([torch.tensor([0.0]), self.b])\n",
    "        i = torch.arange(len(self.a), 0, -1).to(torch.float32)\n",
    "        j = torch.arange(len(self.b), 0, -1).to(torch.float32)\n",
    "        smooth_a = (torch.diff(a) ** 2) @ (i ** 2) / len(self.a)\n",
    "        smooth_b = (torch.diff(b) ** 2) @ (j ** 2) / len(self.b)\n",
    "        return smooth_a + smooth_b\n",
    "            \n",
    "    @classmethod\n",
    "    def from_params(cls, params, freeze_g=True):\n",
    "        g = PolynomialActivation.from_params(params[\"g\"])\n",
    "        model = cls(g, len(model.a), len(model.b), params[\"bin_size\"], freeze_g=freeze_g)\n",
    "        model.a = torch.nn.Parameter(params[\"a\"])\n",
    "        model.b = torch.nn.Parameter(params[\"b\"])\n",
    "        model.k = len(model.a)\n",
    "        model.l = len(model.b)\n",
    "        return model\n",
    "    \n",
    "    @classmethod\n",
    "    def from_ekfr(cls, ekfr_model, k, l, freeze_g=True):\n",
    "        g = PolynomialActivation.from_params(ekfr_model.g.get_params())\n",
    "        model = cls(g, k, l, ekfr_model.bin_size, freeze_g=freeze_g)\n",
    "        a = torch.tensor([ekfr_model.kernel(i, var=\"a\") for i in range(k-1, -1, -1)]).to(torch.float32)\n",
    "        b = torch.tensor([ekfr_model.kernel(i, var=\"b\") for i in range(l-1, -1, -1)]).to(torch.float32)\n",
    "        model.a = torch.nn.Parameter(a)\n",
    "        model.b = torch.nn.Parameter(b)\n",
    "        return model\n",
    "\n",
    "    def get_params(self):\n",
    "        return {\n",
    "            \"a\": self.a.detach().cpu(),\n",
    "            \"b\": self.b.detach().cpu(),\n",
    "            \"g\": self.g.get_params(),\n",
    "            \"bin_size\": self.bin_size\n",
    "        }\n",
    "    \n",
    "    def freeze_parameters(self):\n",
    "        for _, p in self.named_parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "    def unfreeze_parameters(self):\n",
    "        for _, p in self.named_parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "    def predict(self, Is):\n",
    "        k, l = self.k, self.l\n",
    "        pad = max(k, l)\n",
    "        Is_pad = F.pad(Is, (pad, 0), \"constant\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            fs1 = torch.zeros(pad)\n",
    "            pred_fs = []\n",
    "            for i in range(pad, len(Is_pad)):\n",
    "                f = self.forward(Is_pad[:i+1], fs1[:i])\n",
    "                fs1 = torch.cat((fs1, f.reshape(1)))\n",
    "                pred_fs.append(f)\n",
    "        return np.array([f.item() for f in pred_fs])\n",
    "    \n",
    "class ExponentialKernelFiringRateModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        g, # activation function\n",
    "        ds,\n",
    "        bin_size,\n",
    "        freeze_g = True,\n",
    "        device = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.g = g\n",
    "        self.bin_size = bin_size\n",
    "        \n",
    "        self.ds = torch.nn.Parameter(ds.clone().detach(), requires_grad=False)\n",
    "        self.n = len(self.ds)\n",
    "        self.a = torch.nn.Parameter(torch.ones(self.n) + torch.randn(self.n) * 0.001)\n",
    "        self.b = torch.nn.Parameter(torch.randn(self.n) * 0.001)\n",
    "        self.w = torch.nn.Parameter((torch.randn(self.n) * 0.001 + 1) / self.n).reshape(-1, 1).to(device)\n",
    "        \n",
    "        if freeze_g: self.g.freeze_parameters()\n",
    "            \n",
    "    \n",
    "    # outputs a tensor of shape [B], firing rate predictions at time t\n",
    "    def forward(\n",
    "        self,\n",
    "        currents, # shape [B], currents for time t\n",
    "        fs # shape [B], firing rates for time t-1\n",
    "    ):\n",
    "        x = torch.outer(currents, self.a) # shape [B, n]\n",
    "        y = 1000 * torch.outer(fs, self.b) # shape [B, n]\n",
    "        self.v =  (1 - self.ds) * self.v + x + y # shape [B, n]\n",
    "        return self.g(self.v @ self.w).reshape(-1) # shape [B]\n",
    "    \n",
    "    def reset(self, batch_size):\n",
    "        self.v = torch.zeros(batch_size, self.n).to(self.device)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_params(cls, params, freeze_g=True):\n",
    "        g = PolynomialActivation.from_params(params[\"g\"])\n",
    "        model = cls(g, params[\"ds\"], params[\"bin_size\"] if \"bin_size\" in params else 20, freeze_g=freeze_g)\n",
    "        model.a = torch.nn.Parameter(params[\"a\"])\n",
    "        model.b = torch.nn.Parameter(params[\"b\"])\n",
    "        model.w = torch.nn.Parameter(params[\"w\"])\n",
    "        return model\n",
    "\n",
    "    def get_params(self):\n",
    "        return {\n",
    "            \"a\": self.a.detach().cpu(),\n",
    "            \"b\": self.b.detach().cpu(),\n",
    "            \"g\": self.g.get_params(),\n",
    "            \"w\": self.w.detach().cpu(),\n",
    "            \"ds\": self.ds.detach().cpu(),\n",
    "            \"bin_size\": self.bin_size\n",
    "        }\n",
    "    \n",
    "    def freeze_parameters(self):\n",
    "        for _, p in self.named_parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "    def unfreeze_parameters(self):\n",
    "        for _, p in self.named_parameters():\n",
    "            p.requires_grad = True\n",
    "            \n",
    "    def kernel(self, x, var=\"a\"):\n",
    "        a = self.a if var == \"a\" else self.b\n",
    "        return torch.sum(self.w * a * torch.pow(self.ds, x))\n",
    "    \n",
    "    # Is: shape [seq_length]\n",
    "    def predict(self, Is):\n",
    "        pred_fs = []\n",
    "        vs = []\n",
    "        f = torch.zeros(1).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            self.reset(1)\n",
    "            for i in range(len(Is)):\n",
    "                f = self.forward(Is[i].reshape(1), f.reshape(1))\n",
    "                vs.append(self.v.clone())\n",
    "                pred_fs.append(f.clone())\n",
    "        return torch.stack(pred_fs).squeeze(), torch.stack(vs).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86c7ac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(save_path=\"model/params/\"):\n",
    "    params = {}\n",
    "    for fname in os.listdir(save_path):\n",
    "        with open(f\"{save_path}{fname}\", \"rb\") as f:\n",
    "            p = pickle.load(f)\n",
    "            params[int(fname.split(\".\")[0])] = p\n",
    "    return params\n",
    "\n",
    "def get_random_neurons(n_neurons, save_path=\"model/params/\", threshold=0.7):\n",
    "    params = get_params(save_path)\n",
    "    cell_ids = []\n",
    "\n",
    "    for cell_id in params:\n",
    "        if params[cell_id][\"evr\"] >= threshold:\n",
    "            cell_ids.append(cell_id)\n",
    "\n",
    "    chosen_ids = random.sample(cell_ids, k=n_neurons)\n",
    "    neurons = []\n",
    "    for cell_id in chosen_ids:\n",
    "        neurons.append((cell_id, ExponentialKernelFiringRateModel.from_params(params[cell_id][\"params\"])))\n",
    "    return neurons\n",
    "\n",
    "class Network(torch.nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.out_dim = out_dim\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(in_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = torch.nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "        self.hidden_neurons = BatchEKFR(get_random_neurons(hidden_dim), freeze_g=True)\n",
    "        self.hidden_neurons.freeze_parameters()\n",
    "    \n",
    "    def reset(self, batch_size):\n",
    "        self.hidden_neurons.reset(batch_size)\n",
    "        self.xh = torch.zeros(batch_size, self.hidden_dim)\n",
    "        \n",
    "    def zero_input(self, batch_size):\n",
    "        return torch.zeros(batch_size, in_dim)\n",
    "    \n",
    "    # x: [batch_size, in_dim]\n",
    "    def forward(self, x):\n",
    "        x_in = self.fc1(x)\n",
    "        x_rec = self.fc2(self.xh)\n",
    "        self.xh = self.hidden_neurons(x_in + x_rec)\n",
    "        out = self.fc3(self.xh)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63224a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(batch_size):\n",
    "    train_set = torchvision.datasets.MNIST('data/mnist/train', download=True, train=True, transform=torchvision.transforms.ToTensor())\n",
    "    test_set = torchvision.datasets.MNIST('data/mnist/test', download=True, train=False, transform=torchvision.transforms.ToTensor())\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "    return train_loader, test_loader\n",
    "    \n",
    "# x: shape [batch_size, 28, 28]\n",
    "# returns shape [batch_size, seq_length, in_dim]\n",
    "def reshape_image(x, variant=\"p\"):\n",
    "    if variant == \"p\":\n",
    "        return x.reshape(x.shape[0], -1, 1)\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def train_network(model, train_loader, epochs, variant=\"p\"):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    #optimizer = torch.optim.RMSprop(model.parameters(), lr=0.1, centered=True)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.03)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "\n",
    "        for x, label in tqdm(train_loader):\n",
    "            x = x.reshape(x.shape[0], 28, 28)\n",
    "            x = reshape_image(x, variant=variant)\n",
    "            \n",
    "            # sequentially send input into network\n",
    "            model.reset(x.shape[0])\n",
    "            for i in range(x.shape[1]):\n",
    "                model(x[:, i, :])\n",
    "                \n",
    "            loss = 0\n",
    "            for _ in range(5):\n",
    "                pred_y = model(model.zero_input(x.shape[0]))\n",
    "                loss += criterion(pred_y, F.one_hot(label, num_classes=10).to(torch.float32))\n",
    "            loss /= 5\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss\n",
    "            \n",
    "        if (epoch+1) % 1 == 0:\n",
    "            print(f\"Epoch {epoch+1} / Loss: {total_loss}\")\n",
    "            \n",
    "def accuracy(model, data_loader, variant=\"p\"):\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        for x, label in tqdm(data_loader):\n",
    "            x = x.reshape(x.shape[0], 28, 28)\n",
    "            x = reshape_image(x, variant=variant)\n",
    "\n",
    "            # sequentially send input into network\n",
    "            model.reset(x.shape[0])\n",
    "            for i in range(x.shape[1]):\n",
    "                model(x[:, i, :])\n",
    "\n",
    "            total_pred = torch.zeros(x.shape[0], 10)\n",
    "            for _ in range(5):\n",
    "                pred_y = model(model.zero_input(x.shape[0]))\n",
    "                total_pred += F.softmax(pred_y, dim=1) # add softmax\n",
    "            correct += torch.sum(torch.argmax(total_pred, dim=1) == label)\n",
    "            total += x.shape[0]\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7d1f3fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:12<00:00, 18.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / Loss: 541.18408203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:13<00:00, 17.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 / Loss: 541.1002807617188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:13<00:00, 17.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 / Loss: 541.1058959960938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:13<00:00, 17.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / Loss: 541.1051025390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:13<00:00, 17.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 / Loss: 541.0718994140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:13<00:00, 17.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 / Loss: 541.1148681640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:13<00:00, 17.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / Loss: 541.1693115234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:13<00:00, 17.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 / Loss: 541.1134033203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:13<00:00, 17.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 / Loss: 541.1106567382812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:13<00:00, 17.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 / Loss: 541.1167602539062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:13<00:00, 17.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 / Loss: 541.1646728515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:14<00:00, 16.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 / Loss: 541.0778198242188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:14<00:00, 16.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 / Loss: 541.0667114257812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:13<00:00, 17.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 / Loss: 541.1650390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:13<00:00, 17.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 / Loss: 541.087890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:13<00:00, 17.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 / Loss: 541.1319580078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:13<00:00, 17.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 / Loss: 541.1241455078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:13<00:00, 17.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 / Loss: 541.123046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:13<00:00, 17.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 / Loss: 541.0089111328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:13<00:00, 17.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 / Loss: 541.1427001953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:13<00:00, 17.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 / Loss: 541.044189453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:13<00:00, 17.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 / Loss: 541.0504760742188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:14<00:00, 16.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 / Loss: 541.11669921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:13<00:00, 16.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 / Loss: 541.073974609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:13<00:00, 17.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 / Loss: 541.0989990234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:13<00:00, 17.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 / Loss: 541.05615234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:13<00:00, 17.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 / Loss: 541.1557006835938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:13<00:00, 16.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 / Loss: 541.0872802734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:13<00:00, 17.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 / Loss: 541.1174926757812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:13<00:00, 16.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 / Loss: 541.1862182617188\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "variant = \"l\"\n",
    "in_dim = 1 if variant == \"p\" else 28\n",
    "out_dim = 10\n",
    "hidden_dim = 32\n",
    "epochs = 30\n",
    "train_loader, test_loader = get_data_loaders(batch_size)\n",
    "model = Network(in_dim, hidden_dim, out_dim)\n",
    "train_network(model, train_loader, epochs, variant=variant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7081afeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [00:07<00:00, 33.53it/s]\n",
      "100%|███████████████████████████████████████████| 40/40 [00:01<00:00, 32.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.11236666887998581 / Test accuracy: 0.11349999904632568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_acc = accuracy(model, train_loader, variant=variant)\n",
    "test_acc = accuracy(model, test_loader, variant=variant)\n",
    "print(f\"Train accuracy: {train_acc} / Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9707b8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(model.Wh.detach())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aef1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(model.Wx.detach())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201461fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(model.Wy.detach())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dd5e4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_random_neurons(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d963b3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [GeneralizedFiringRateModel.from_ekfr(model, 10, 10) for _, model in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d295446d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "485932822\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/processed_data/processed_I_and_firing_rate_485932822.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m cell_id \u001b[38;5;241m=\u001b[39m a[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(cell_id)\n\u001b[0;32m----> 5\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maligned\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m Is_tr, fs_tr, Is_val, fs_val, Is_te, fs_te, stims \u001b[38;5;241m=\u001b[39m get_train_test_data(data, \u001b[38;5;241m20\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/GRNN/data.py:11\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(cell_id, aligned)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_data\u001b[39m(cell_id, aligned\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     10\u001b[0m     path \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_path_aligned\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m aligned \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_path\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessed_I_and_firing_rate_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcell_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/processed_data/processed_I_and_firing_rate_485932822.pickle'"
     ]
    }
   ],
   "source": [
    "from evaluate import explained_variance_ratio\n",
    "from data import get_train_test_data, get_data\n",
    "cell_id = a[0][0]\n",
    "print(cell_id)\n",
    "data = get_data(cell_id, aligned=False)\n",
    "Is_tr, fs_tr, Is_val, fs_val, Is_te, fs_te, stims = get_train_test_data(data, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc69322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
