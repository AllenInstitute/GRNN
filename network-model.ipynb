{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2019eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from network import Network\n",
    "from data import get_MNIST_data_loaders\n",
    "from train import train_network\n",
    "from evaluate import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d1f3fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"{device=}\")\n",
    "\n",
    "variant = \"l\"\n",
    "in_dim = 1 if variant == \"p\" else 28\n",
    "hidden_dim = 64\n",
    "out_dim = 10\n",
    "batch_size = 256\n",
    "\n",
    "train_loader, test_loader = get_MNIST_data_loaders(batch_size, variant=variant)\n",
    "model = Network(\n",
    "    in_dim, \n",
    "    hidden_dim, \n",
    "    out_dim, \n",
    "    neuron_type=\"ekfr\", \n",
    "    freeze_neurons=False, \n",
    "    freeze_g=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6100eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_network(\n",
    "    model, \n",
    "    train_loader, \n",
    "    epochs=30, \n",
    "    lr=0.05, \n",
    "    variant=variant,\n",
    "    C=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a22ffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = accuracy(model, train_loader, variant=variant, device=device)\n",
    "test_acc = accuracy(model, test_loader, variant=variant, device=device)\n",
    "print(f\"Train accuracy: {train_acc} | Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19566973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_network(fname):\n",
    "    state = torch.load(fname)\n",
    "    model = Network(\n",
    "        1 if state[\"variant\"] == \"p\" else 28, \n",
    "        state[\"hidden_dim\"], \n",
    "        10, \n",
    "        neuron_type=state[\"neuron_type\"], \n",
    "        freeze_neurons=state[\"freeze_neurons\"], \n",
    "        freeze_g=state[\"freeze_activations\"]\n",
    "    )\n",
    "    model.load_state_dict(state[\"model_state_dict\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e3ddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_network(\"model/network_params/l_ekfr_64_True_True.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617a13e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xs = torch.linspace(0, 20, 100)\n",
    "xss = torch.stack([xs for _ in range(hidden_dim)], dim=1)\n",
    "ys_a = torch.stack([model.hidden_neurons.kernel(x, var=\"a\") for x in xs]).detach()\n",
    "ys_b = torch.stack([model.hidden_neurons.kernel(x, var=\"b\") for x in xs]).detach()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(xss, ys_a, alpha=0.5)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(xss, ys_b, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93c8c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.load(\"model/network_params/l_ekfr_128_True_True.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f638276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e16e591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    Is_tr,\n",
    "    fs_tr,\n",
    "    epochs: int = 100,\n",
    "    print_every: int = 10,\n",
    "    bin_size = 20,\n",
    "    up_factor = 10,\n",
    "    scheduler = None\n",
    "):\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for Is, fs in zip(Is_tr, fs_tr):\n",
    "            batch_size = Is.shape[0]\n",
    "            loss = torch.zeros(batch_size).to(model.device)\n",
    "            model.reset(batch_size)\n",
    "            \n",
    "            for i in range(Is.shape[1]):\n",
    "                f = model(Is[:, i])\n",
    "                \n",
    "                # up-weight loss for non-zero firing rate\n",
    "                alpha = torch.ones(batch_size).to(model.device)\n",
    "                alpha[torch.logical_or(fs[:, i] > 0, f > 0)] = up_factor\n",
    "                loss += alpha * criterion(f * bin_size, fs[:, i] * bin_size)\n",
    "            \n",
    "            mean_loss = torch.mean(loss)\n",
    "            optimizer.zero_grad()\n",
    "            mean_loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += mean_loss.item()\n",
    "        losses.append(total_loss)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        if (epoch+1) % print_every == 0:\n",
    "            if scheduler is None:\n",
    "                print(f\"Epoch {epoch+1} | Loss: {total_loss}\")\n",
    "            else:\n",
    "                curr_lr = scheduler.get_last_lr()\n",
    "                print(f\"Epoch {epoch+1} | Loss: {total_loss} | lr: {curr_lr}\")\n",
    "\n",
    "        if len(losses) >= 3 and losses[-1] == losses[-2] == losses[-3]:\n",
    "            return losses\n",
    "        \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f50458ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExponentialKernelFiringRateModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        g, # activation function\n",
    "        ds,\n",
    "        bin_size,\n",
    "        freeze_g = True,\n",
    "        device = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.g = g\n",
    "        self.bin_size = bin_size\n",
    "        self.device = device\n",
    "        \n",
    "        self.ds = torch.nn.Parameter(ds.clone().detach(), requires_grad=False)\n",
    "        self.n = len(self.ds)\n",
    "        self.a = torch.nn.Parameter(torch.ones(self.n) + torch.randn(self.n) * 0.001)\n",
    "        self.b = torch.nn.Parameter(torch.randn(self.n) * 0.001)\n",
    "        \n",
    "        if freeze_g: self.g.freeze_parameters()\n",
    "            \n",
    "    \n",
    "    # outputs a tensor of shape [B], firing rate predictions at time t\n",
    "    def forward(\n",
    "        self,\n",
    "        currents # shape [B], currents for time t\n",
    "    ):\n",
    "        x = torch.outer(currents, self.a) # shape [B, n]\n",
    "        y = 1000 * torch.outer(self.fs, self.b) # shape [B, n]\n",
    "        self.v =  (1 - self.ds) * self.v + x + y # shape [B, n]\n",
    "        print(self.v.shape)\n",
    "        self.fs = self.g(torch.mean(self.v, dim=1).unsqueeze(1)) # shape [B]\n",
    "        return self.fs\n",
    "    \n",
    "    def reset(self, batch_size):\n",
    "        self.v = torch.zeros(batch_size, self.n).to(self.device)\n",
    "        self.fs = torch.zeros(batch_size).to(self.device)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_params(cls, params, freeze_g=True, device=None):\n",
    "        g = PolynomialActivation.from_params(params[\"g\"])\n",
    "        model = cls(g, params[\"ds\"], params[\"bin_size\"], freeze_g=freeze_g, device=device)\n",
    "        model.a = torch.nn.Parameter(params[\"a\"])\n",
    "        model.b = torch.nn.Parameter(params[\"b\"])\n",
    "        return model\n",
    "\n",
    "    def get_params(self):\n",
    "        return {\n",
    "            \"a\": self.a.detach().cpu(),\n",
    "            \"b\": self.b.detach().cpu(),\n",
    "            \"g\": self.g.get_params(),\n",
    "            \"ds\": self.ds.detach().cpu(),\n",
    "            \"bin_size\": self.bin_size\n",
    "        }\n",
    "    \n",
    "    def freeze_parameters(self):\n",
    "        for _, p in self.named_parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "    def unfreeze_parameters(self): # problematic\n",
    "        for _, p in self.named_parameters():\n",
    "            p.requires_grad = True\n",
    "            \n",
    "    def kernel(self, x, var=\"a\"):\n",
    "        a = self.a if var == \"a\" else self.b\n",
    "        return torch.sum(a * torch.pow(1-self.ds, x))\n",
    "    \n",
    "    # Is: shape [seq_length]\n",
    "    def predict(self, Is):\n",
    "        pred_fs = []\n",
    "        vs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            self.reset(1)\n",
    "            for i in range(len(Is)):\n",
    "                f = self.forward(Is[i].reshape(1))\n",
    "                vs.append(self.v.clone())\n",
    "                pred_fs.append(f.clone())\n",
    "        return torch.stack(pred_fs).squeeze(), torch.stack(vs).squeeze()\n",
    "    \n",
    "class PolynomialActivation(torch.nn.Module):\n",
    "    def __init__(self, degree, max_current, max_firing_rate, bin_size):\n",
    "        super().__init__()\n",
    "        self.degree = degree\n",
    "        self.max_current = max_current\n",
    "        self.max_firing_rate = max_firing_rate\n",
    "        self.bin_size = bin_size\n",
    "        \n",
    "        self.p = torch.nn.Parameter(torch.tensor([d for d in range(degree+1)]), requires_grad=False)\n",
    "        self.poly_coeff = torch.nn.Parameter(torch.randn(self.degree + 1))\n",
    "        self.b = torch.nn.Parameter(torch.tensor(0.0))\n",
    "    \n",
    "    # z: shape [B, 1]\n",
    "    def forward(self, z):\n",
    "        x = (z - self.b) / self.max_current # shape [B, n]\n",
    "        poly = torch.einsum(\"ijk,jk->ij\", x.unsqueeze(dim=2).pow(self.p.reshape(1, 1, -1)), self.poly_coeff ** 2) # shape [B, n]\n",
    "        tan = self.max_firing_rate * F.tanh(poly) # ceil is the max firing rate\n",
    "        return F.relu(tan).to(torch.float32) # shape [B, n]\n",
    "    \n",
    "    # initialize based on linear approximation of data\n",
    "    @classmethod\n",
    "    def from_data(cls, degree, max_current, max_firing_rate, bin_size, Is, fs):\n",
    "        g = cls(degree, max_current, max_firing_rate, bin_size)\n",
    "        \n",
    "        x1, x2, y1, y2 = tuple([torch.tensor(0.0)] * 4)\n",
    "        xs, ys = map(list, zip(*sorted(zip(Is.cpu(), fs.cpu()), key=lambda x: x[0])))\n",
    "        i = np.argmax(ys)\n",
    "        x2, y2 = xs[i], ys[i]\n",
    "        for i in range(0, len(ys)):\n",
    "            if ys[i] > 0.01:\n",
    "                x1, y1 = (xs[i-1], ys[i-1]) if i - 1 > 0 else (xs[i], ys[i])\n",
    "                break\n",
    "                \n",
    "        g.b = torch.nn.Parameter(x1.clone())\n",
    "        poly_coeff = torch.randn(degree + 1) * 1e-1\n",
    "        poly_coeff[1] = np.abs((y2 - y1) / (x2 - x1) * max_current)\n",
    "        g.poly_coeff = torch.nn.Parameter(poly_coeff)\n",
    "        \n",
    "        return g\n",
    "    \n",
    "    @classmethod\n",
    "    def from_params(cls, params):\n",
    "        poly_coeff = torch.nn.Parameter(params[\"poly_coeff\"])\n",
    "        degree = len(poly_coeff) - 1\n",
    "        max_current = params[\"max_current\"]\n",
    "        max_firing_rate = params[\"max_firing_rate\"]\n",
    "        bin_size = params[\"bin_size\"]\n",
    "        g = cls(degree, max_current, max_firing_rate, bin_size)\n",
    "        g.poly_coeff = poly_coeff\n",
    "        g.b = torch.nn.Parameter(params[\"b\"])\n",
    "        return g\n",
    "\n",
    "    def get_params(self):\n",
    "        return {\n",
    "            \"max_current\": self.max_current,\n",
    "            \"max_firing_rate\": self.max_firing_rate,\n",
    "            \"poly_coeff\": self.poly_coeff.detach().cpu(),\n",
    "            \"b\": self.b.detach().cpu(),\n",
    "            \"bin_size\": self.bin_size\n",
    "        }\n",
    "    \n",
    "    def freeze_parameters(self):\n",
    "        for _, p in self.named_parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "    def unfreeze_parameters(self):\n",
    "        for _, p in self.named_parameters():\n",
    "            p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25424c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = PolynomialActivation(1, 100, 100, 20)\n",
    "model = ExponentialKernelFiringRateModel(g, torch.tensor([1, 2, 3, 4, 5]).to(torch.float32), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7b3273f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0374],\n",
       "        [0.0374],\n",
       "        [0.0374],\n",
       "        [0.0374],\n",
       "        [0.0374],\n",
       "        [0.0374],\n",
       "        [0.0374],\n",
       "        [0.0374],\n",
       "        [0.0374],\n",
       "        [0.0374]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.reset(10)\n",
    "model(torch.ones(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c561bd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(torch.ones(10,5), dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e140b7aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
